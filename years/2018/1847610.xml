<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Scientific Foundations for Augmented Human Performance in Robotic Surgery</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2019</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Scheidt</SignBlockName>
<PO_EMAI>rscheidt@nsf.gov</PO_EMAI>
<PO_PHON>7032922477</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Some surgical procedures are challenging to perform because they demand speed and precision of instrument control that tax the limits of even the most skilled surgeons.  This Faculty Early Career Development Program (CAREER) project is based on the premise that intelligent surgical robotics can elevate skilled performance of precision manual tasks by melding the high-level planning and adaptability of the human surgeon with the superhuman speed and precision of a hand-held robotic tool. The specific application to be studied and modeled is 3D printing of biologically-compatible materials directly onto moving human anatomy using hand-held, robotic, bio-jet technology.  This is an example of a new convergent discipline, which the PI calls "computational co-surgery." Here, the handheld robot shares control of the bio-jet with the surgeon. Realizing the full potential of the human / robot dyad will require seamless cooperation and a dynamic tradeoff between speed and accuracy to deal with unpredictable target motions. This in turn requires the human surgeon to monitor and evaluate the quality and intent of the robot's motions as they unfold at high speed. The project will quantify the ability of humans to perceive and characterize visual feedback of tool motion at high speeds using a novel crowd-sourcing approach. Seamless cooperation also requires that the surgeon exert high-bandwidth control over the hand-held device. The proposal will explore the extent to which voluntary modulation of limb reflex responses can facilitate low-latency monitoring and control operations. The project also includes several annual outreach events where participants use handheld robots to discover and learn about computational co-surgery and human-robot shared control.  As such, this CAREER project promotes the progress of science, advances the national health, and contributes to the development of the STEM workforce, with efforts to attract students from underrepresented minority populations. &lt;br/&gt;&lt;br/&gt;The PI will advance a new interdisciplinary field of study termed "computational co-surgery" through a project that will ultimately enable 3D printing of bio-materials directly onto moving human anatomy using hand-held, robotic technology.  The project combines elements of psychology (visual perception), engineering (robotic design and control), and physiology (sensorimotor control) to promote the ability of the human surgeon to leverage the speed and precision of a hand-held robotic tool. In the case to be studied, an intelligent robot and a human surgeon share control of a surgical instrument, with touch and proprioception as the feedback channels and limb stiffness modulation as the actuation method. The research objective is to measure how humans perceive (Aim 1) and interact with (Aim 2) objects that move with high speed (&lt;1kHz bandwidth) and precision (~50 um).  Aim 1 will use Amazon Mechanical Turk to test the working hypothesis that when viewing tool manipulations, assessments of skill reflect a trade-off between movement speed and movement quality (precision) subject to psychological factors including internal models of limb and object dynamics, and stimulus coherence in multisensory integration.  Further, the project will explore the utility of touch and proprioception (feedback) and limb stiffness modulation (actuation) to realize low-latency, non-invasive bidirectional human-robot monitoring and control. Aim 2 will use a customized hand-held robot with high- and low-inertia modes and a Fitts pointing task to test the working hypotheses that: 1) limb stiffness modulation is a fast and effective means of quickly ceding control between robot and human intent during manipulations requiring high speed and precision; and 2) humans naturally modulate effective stiffness at the hand-robot interface via long-latency reflex action (i.e., without lengthy training).  Accomplishing these Aims will advance the fundamental science of handheld collaborative robots that cope with unpredictable human motion or human intent. The educational goal includes an outreach plan where participants are invited to use a small hand-held robot to see if they can "perform better than the best surgeon" in mock surgical tasks.  Sites span classroom settings, public events, and international acconferences attended by clinicians and engineers.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/08/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/08/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1847610</AwardID>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>Kowalewski</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy M Kowalewski</PI_FULL_NAME>
<EmailAddress>timk@umn.edu</EmailAddress>
<PI_PHON>6126245599</PI_PHON>
<NSF_ID>000635840</NSF_ID>
<StartDate>02/08/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName/>
<StateCode>MN</StateCode>
<ZipCode>554552070</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>058Y</Code>
<Text>M3X - Mind, Machine, and Motor</Text>
</ProgramElement>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramReference>
<Code>060Z</Code>
<Text>Convergent Research</Text>
</ProgramReference>
<ProgramReference>
<Code>063Z</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7632</Code>
<Text>HUMAN-ROBOT INTERACTION</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~500000</FUND_OBLG>
</Award>
</rootTag>
