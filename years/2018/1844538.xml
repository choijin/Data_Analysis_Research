<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Automatic and general light transport algorithms for use by humans and machines</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2019</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>549922.00</AwardTotalIntnAmount>
<AwardAmount>302567</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer graphics rendering uses light transport simulation to virtually "capture" photographs. While its evolution has largely mirrored that of photography, the state of graphics today is unfortunately like that of photography in the mid-1900s when creating a good image required being a trained professional with an intimate understanding of light and the peculiarities of the available tools. Since then, photography has witnessed a revolution where smartphone cameras produce technically superior images while hiding this complexity; this democratization has enabled a vast array of new applications. The goal of the current project is to enable the same revolution for the "virtual photographs" created using computer graphics algorithms. This will require developing new ways of expressing numerical light transport simulations which relax current assumptions on the input and output of the rendering process, leading to automatic "point and click" rendering algorithms which avoid manual parameter tuning. Project outcomes will have far-reaching and broad impact on all application areas that currently rely on accurate and efficient light transport simulation, from diagnosing illnesses, to self-driving cars, to video games and films, to designing and manufacturing products. More importantly, they will democratize these tools beyond trained professionals, much like "point and shoot" smartphone cameras have done for photography. An integrated educational and outreach program will increase diversity and support underrepresented groups by building on the host institution's existing strengths in STEM and Digital Arts, and will leverage the appeal of animated films to teach otherwise abstract mathematics and physics concepts to students from a broad range of ages and socio-economic backgrounds.&lt;br/&gt;&lt;br/&gt;While computer graphics rendering can produce the realistic and beautiful imagery we see in movies today, the algorithms used to achieve these results are brittle and require tuning by skilled practitioners. They focus almost entirely on mimicking traditional camera/optical systems that were designed for use by people, which limits their applicability to emerging imaging modalities. And they still struggle to render common scenes due to unrealistic assumptions about the physical world and the light transport within it. Broadening the reach of computer graphics requires addressing these core challenges. Firstly, this project will establish a new framework for expressing Monte Carlo light transport strategies and a method to computationally determine which ones should be used on which scenes. This will lead to more robust and automatic "point and click" rendering algorithms which avoid manual parameter tuning with heuristics. The research will also extend current rendering approaches beyond 2D RGB images for broader impact on inverse problems using modern imaging systems. Lastly, the work will lift long-held statistical assumptions about light transport and scene/material representations, laying the theoretical and algorithmic foundation for universal level of detail and increased artistic control. Project outcomes will have far-reaching impact in all application domains relying on computer graphics rendering, and will add valuable basic knowledge about non-classical transport to related domains like nuclear engineering and atmospheric science. More broadly, the work will shift the focus of future rendering research towards robust and automatic rendering algorithms to democratize these tools beyond computer graphics professionals.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/11/2019</MinAmdLetterDate>
<MaxAmdLetterDate>04/26/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1844538</AwardID>
<Investigator>
<FirstName>Wojciech</FirstName>
<LastName>Jarosz</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wojciech Jarosz</PI_FULL_NAME>
<EmailAddress>wojciech.k.jarosz@dartmouth.edu</EmailAddress>
<PI_PHON>6036468721</PI_PHON>
<NSF_ID>000703281</NSF_ID>
<StartDate>03/11/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Dartmouth College</Name>
<CityName>HANOVER</CityName>
<CountyName/>
<ZipCode>037551421</ZipCode>
<PhoneNumber>6036463007</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROJECTS</StreetAddress>
<StreetAddress2><![CDATA[11 ROPE FERRY RD #6210]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041027822</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF DARTMOUTH COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041027822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dartmouth College]]></Name>
<CityName>Hanover</CityName>
<CountyName/>
<StateCode>NH</StateCode>
<ZipCode>037553510</ZipCode>
<StreetAddress><![CDATA[6211 Sudikoff]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NH02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~76319</FUND_OBLG>
<FUND_OBLG>2020~110612</FUND_OBLG>
<FUND_OBLG>2021~115636</FUND_OBLG>
</Award>
</rootTag>
