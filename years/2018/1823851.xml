<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: The perception of acoustic-phonetic cues and its impact on speech category learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>02/29/2020</AwardExpirationDate>
<AwardTotalIntnAmount>15247.00</AwardTotalIntnAmount>
<AwardAmount>15247</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tyler Kendall</SignBlockName>
<PO_EMAI>tkendall@nsf.gov</PO_EMAI>
<PO_PHON>7032922434</PO_PHON>
</ProgramOfficer>
<AbstractNarration>To understand speech, we must be able to recognize and distinguish the sounds in our language. For example, when we hear the first sound in 'toe' and in 'tall', we must identify them as two instances of the same sound, /t/, that are distinct from other sounds such as /d/ at the beginning of 'doe'. This is a remarkable feat given that each speech sound is characterized by a host of acoustic properties. Thus, one question that has interested researchers in speech perception is how listeners decide what acoustic properties to pay attention to and what acoustic properties to ignore. Listeners may learn this purely based on experience. That is, based on exposure to the speech sounds in their native language, they come to know that the difference between /t/ vs /d/ is signaled by a specific set of acoustic properties that are most informative to the contrast. Listeners may also attend to cues based on the relationship the cues have with each other. For example, if two cues are perceptually inseparable, then attending to one means necessarily attending to the other.This dissertation research may lead to insights in how to improve second language instruction and may inform work for technologies on speech synthesis in minority languages.&lt;br/&gt;&lt;br/&gt;The goal of this project is to understand how listener's language experience and the inherent relation between acoustic properties affect speech perception. With perception experiments the researchers propose to compare how listeners use two pairs of acoustic properties when categorizing speech sounds. One pair has been shown to be perceptually inseparable, and another pair is perceptually independent. Two groups of listeners will be tested: English listeners who have no language experience with either pair of properties, and Hani (Tibeto-Burman - Yunnan, China) listeners who have language experience with both pairs of properties. Manipulating experience as well as the relation between pairs will enable the researchers to disambiguate the role of experience from that of perceptual separability. Additionally, as part of the proposed project an undergraduate student will be trained in linguistic fieldwork and experimental research methods.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/02/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1823851</AwardID>
<Investigator>
<FirstName>Megha</FirstName>
<LastName>Sundara</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Megha Sundara</PI_FULL_NAME>
<EmailAddress>megha.sundara@humnet.ucla.edu</EmailAddress>
<PI_PHON>3108250041</PI_PHON>
<NSF_ID>000496434</NSF_ID>
<StartDate>08/02/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meng</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meng Yang</PI_FULL_NAME>
<EmailAddress>mengyang@g.ucla.edu</EmailAddress>
<PI_PHON>4243247135</PI_PHON>
<NSF_ID>000766716</NSF_ID>
<StartDate>08/02/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Los Angeles]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951543</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8374</Code>
<Text>DDRI Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~15247</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span lang="EN-US">This dissertation research investigated the extent to which human listeners rely on the different physical dimensions (cues) of speech sounds to distinguish them. We specifically wanted to address whether experience alone determines the extent to which listeners rely on specific acoustic cues, or if there is a role for the enhancing relationship between the cues themselves.</span></p> <p><span lang="EN-US">We compared listeners&rsquo; perception of two sets of cues, enhancing vs. non-enhancing, while simultaneously controlling for their experience with these cues in their native language. We found that the extent to which listeners relied on each of the non-enhancing cues was entirely predicted by their language experience. Listeners without experience learned the weighting of non-enhancing cues for new sound categories to which they were exposed; but listeners with experience extended the weighting of non-enhancing cues from their native language to newly learned sound categories. Listeners with experience also extended the weighting of enhancing cues from their native language to newly learned sound categories. Crucially, listeners without experience also behaved exactly like listeners with experience when tested with enhancing cues. That is, in addition to experience, the enhancing property of the cues themselves independently influenced the extent to which listeners relied on them to signal sound categories.</span></p> <p><span lang="EN-US">We further discovered in a cross-linguistic survey that only enhancing cues participated in historical sound change across the world&rsquo;s languages. Over time, speech sound categories in several different language families that used to be signaled by one of the enhancing cues often came to be signaled by the other. This was not the case for non-enhancing cues. What these results show is that the enhancing relationship between cues observed in the lab can shape the speech sound categories of languages over generations of speakers.</span></p> <p><span lang="EN-US">Beyond the study of speech sounds and language patterns, our results have broader implications in areas such as speech technology and second language learning. In technology, understanding what acoustic properties of speech listeners are sensitive to is crucial for improving text-to-speech systems in various languages for different populations. In second language learning or teaching, understanding the factors that affect and constrain a listener&rsquo;s ability to learn new sound categories is important for predicting the exact contexts where this might be difficult, so they can be targeted during training.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 04/01/2020<br>      Modified by: Meng&nbsp;Yang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This dissertation research investigated the extent to which human listeners rely on the different physical dimensions (cues) of speech sounds to distinguish them. We specifically wanted to address whether experience alone determines the extent to which listeners rely on specific acoustic cues, or if there is a role for the enhancing relationship between the cues themselves.  We compared listeners’ perception of two sets of cues, enhancing vs. non-enhancing, while simultaneously controlling for their experience with these cues in their native language. We found that the extent to which listeners relied on each of the non-enhancing cues was entirely predicted by their language experience. Listeners without experience learned the weighting of non-enhancing cues for new sound categories to which they were exposed; but listeners with experience extended the weighting of non-enhancing cues from their native language to newly learned sound categories. Listeners with experience also extended the weighting of enhancing cues from their native language to newly learned sound categories. Crucially, listeners without experience also behaved exactly like listeners with experience when tested with enhancing cues. That is, in addition to experience, the enhancing property of the cues themselves independently influenced the extent to which listeners relied on them to signal sound categories.  We further discovered in a cross-linguistic survey that only enhancing cues participated in historical sound change across the world’s languages. Over time, speech sound categories in several different language families that used to be signaled by one of the enhancing cues often came to be signaled by the other. This was not the case for non-enhancing cues. What these results show is that the enhancing relationship between cues observed in the lab can shape the speech sound categories of languages over generations of speakers.  Beyond the study of speech sounds and language patterns, our results have broader implications in areas such as speech technology and second language learning. In technology, understanding what acoustic properties of speech listeners are sensitive to is crucial for improving text-to-speech systems in various languages for different populations. In second language learning or teaching, understanding the factors that affect and constrain a listener’s ability to learn new sound categories is important for predicting the exact contexts where this might be difficult, so they can be targeted during training.          Last Modified: 04/01/2020       Submitted by: Meng Yang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
