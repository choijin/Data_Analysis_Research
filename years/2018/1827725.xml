<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Effector and Task Neural Representations of Hand-Object Interactions</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>447432.00</AwardTotalIntnAmount>
<AwardAmount>447432</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project focuses on understanding how people learn, plan, and execute hand movements to grasp and use objects. For example, how does a person lift a cup of coffee without spilling or a factory worker line up a Phillips-head screwdriver with the grooves on a screw? Although we perform these tasks routinely without giving them too much thought, dexterous manipulation is one of the most complex and least understood human skills and one that still limits the utility of robots in industry. Of particular interest is understanding the brain mechanisms that allow people to learn to manipulate an object one way (e.g., to lift a mug by the handle) and then apply that knowledge differently (e.g., to lift the same mug by its sides). The investigators are working towards a comprehensive theory, at both the neural and behavioral levels, of how people learn and generalize these hand-object interactions. The results may inspire new robotic manipulators that are more dexterous, with human-like ability to generalize a learned motor behavior to novel contexts. The work may also influence development of more dexterous neuroprosthetics. The project's other broader impacts include a public lecture and discussion on the social and ethical implications of human-robot systems and participation in the "Science Cafe" series hosted by the Arizona Science Center.&lt;br/&gt;&lt;br/&gt;Previous work by the investigators has provided evidence for two scenarios for learning how to manipulate objects. In one scenario, people build a high-level (i.e., task-level) representation of object manipulation, which allows them to generalize the learned manipulation to a different context. For example, people successfully manipulate an object even after a finger is removed from, or added to, the object's contact surface or when the object is manipulated by the contralateral arm. In a second scenario, people build an effector-level representation. In this case, they persist in generating the same finger placement and forces despite a new context that requires different solutions, as when an object with an asymmetric mass distribution is rotated. What are the neural mechanisms involved with promoting or interfering with generalization of learned hand-object interactions? Can neural representations at the task level - enabling generalization - be built following repeated exposure to a different manipulation context? These questions represent a significant gap in our understanding of skilled object manipulation. The overall goal of this collaborative research is to elucidate neural mechanisms underlying task- and effector-level representations of hand-object interactions. The studies will record finger position and forces utilized when grasping objects in order to probe the influence of the context in which a given hand-object interaction is learned. Electroencephalography (EEG) will be used to determine the neural correlates of successful and unsuccessful generalizations to new contexts. Quantification of these behavioral variables and the corresponding brain mechanisms will provide insights into how objects are mentally represented and how these representations underlie planning and execution of dexterous manipulation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/22/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/22/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1827725</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Gordon</LastName>
<EmailAddress>ag275@columbia.edu</EmailAddress>
<StartDate>08/22/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Teachers College, Columbia University</Name>
<CityName>New York</CityName>
<ZipCode>100276625</ZipCode>
<PhoneNumber>2126783000</PhoneNumber>
<StreetAddress>525 West 120th Street</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>058y</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>1397</Code>
<Text>Cross-Directorate  Activities</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
</Appropriation>
</Award>
</rootTag>
