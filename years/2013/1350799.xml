<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Measuring Search Engines' Ability to Help Users Complete Tasks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2014</AwardEffectiveDate>
<AwardExpirationDate>05/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>550000.00</AwardTotalIntnAmount>
<AwardAmount>550000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The purpose of this project is to improve search systems' ability to help users complete tasks. The usefulness of any search engine ultimately depends on how good it is at aiding its users. The systems and the tasks they are used for can be very complicated; small changes in a system's implementation or a task's execution can have major effects on the usefulness of the system, especially over a long lifespan of use by a large base of people.  The traditional approach to understanding utility involves the use of test collections, which consist of a collection of documents to be searched, unchanging information needs, and human judgments of the relevance of documents to needs; these components are put into a simple batch process that measures search effectiveness and tests simple statistical hypotheses. While this approach is useful, it often fails to capture variability present in users and tasks: different users often interact with the same system in very different ways, meaning a system that is useful for one user or one task may not be useful for another user or task. Therefore, this project focuses on developing new methods for understanding, estimating, and improving the usefulness of information retrieval (IR) systems that take variability into consideration. &lt;br/&gt;&lt;br/&gt;The methods investigated in this project are designed to model user interactions with a system to complete a task, including how users determine relevance in context, how they modify their interaction with a system over time, and how different approaches by different users affect the overall system usefulness. The project will produce new types of test collections, evaluation measures, and statistical methods for batch-style systems-based information retrieval evaluation for use by researchers and practitioners in academia and industry.  The work will demonstrate how to use these both to improve system utility to a population of users as well as to pose deeper hypotheses about causality in IR system development, thus leading to improvements in IR technology in all domains. Research will be integrated with educational activities for students as well as researchers and practitioners to learn advanced experimental design and analysis. Educational efforts will include tutorials and teaching courses on empirical methods in IR and computer science, methods in use in the wider scientific community, and how the newly developed methods relate to those. Results produced from this project can be found on the project web site (http://ir.cis.udel.edu/IIS-1350799).</AbstractNarration>
<MinAmdLetterDate>06/04/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/10/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1350799</AwardID>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Carterette</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin Carterette</PI_FULL_NAME>
<EmailAddress>carteret@udel.edu</EmailAddress>
<PI_PHON>3028312136</PI_PHON>
<NSF_ID>000515818</NSF_ID>
<StartDate>06/04/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Delaware</Name>
<CityName>Newark</CityName>
<ZipCode>197160099</ZipCode>
<PhoneNumber>3028312136</PhoneNumber>
<StreetAddress>210 Hullihen Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<StateCode>DE</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DE00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>059007500</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF DELAWARE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>059007500</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Delaware]]></Name>
<CityName>Newark</CityName>
<StateCode>DE</StateCode>
<ZipCode>197162586</ZipCode>
<StreetAddress><![CDATA[18 Amstel Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DE00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~102766</FUND_OBLG>
<FUND_OBLG>2015~106359</FUND_OBLG>
<FUND_OBLG>2016~109826</FUND_OBLG>
<FUND_OBLG>2017~113575</FUND_OBLG>
<FUND_OBLG>2018~117474</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This award was used to study how people use search systems to complete tasks, and how to use the learnings from those studies to improve search systems in targeted, personalized ways.&nbsp; For the first few years of the award, we focused on search in sessions.&nbsp; A simple example of a task completed in a session is planning a trip: a person may make several searches, to find hotels, flights, attractions, and so on.&nbsp; In such sessions, the user often learns things in the course of their searches, makes decisions, changes their mind, and generally evolves over time.&nbsp; A search engine that can anticipate these changes may better help users.</p> <p>&nbsp;</p> <p>To help study this, we started a cooperative competition, or &ldquo;co-opetition&rdquo;, in which we provided a large dataset of user searches and invited academic and commercial research groups to try to engineer the best search engine for these types of user sessions.&nbsp; It is called a &ldquo;co-opetition&rdquo; because after results are revealed, all groups are required to share how they solved the problem via published, freely-available papers.&nbsp; This enables tech transfer from academic research to industry.&nbsp; IBM and Microsoft were two of the commercial enterprises that participated in our co-opetition.</p> <p>&nbsp;</p> <p>After several years of studying sessions, we transitioned to studying tasks more directly.&nbsp; In collaboration with University College of London, Microsoft, and Google, we began another &ldquo;co-opetition&rdquo; for research groups to build search engines to help users complete tasks.&nbsp; This ran for three years during the award.</p> <p>&nbsp;</p> <p>In the final year of the award, the PI joined Spotify as a visiting research scientist.&nbsp; Spotify provides search and recommendations for music and podcasts.&nbsp; At Spotify the PI was able to participate in tech transfer from academia to industry, particularly learnings from the session and task co-opetitions described above.&nbsp; Furthermore, Spotify has enormous logs of the search and consumption behavior of users, an invaluable tool in understanding how users use these systems and how to improve them.&nbsp; We leveraged this data to develop new methods to rapidly prototype search and recommender systems offline.&nbsp; Some of this work has been integrated into Spotify&rsquo;s development workflows.</p> <p>&nbsp;</p> <p>The work above resulted in dozens of papers published at top-tier venues in computer science.&nbsp; The PI graduated five PhD students who were funded from the award.&nbsp; One of these students was from the West African nation of Togo, a traditionally underrepresented group in computer science.&nbsp; All five are now working in industrial settings in the US.</p> <p>&nbsp;</p> <p>CAREER awards are also about education.&nbsp; Part of the award period was devoted to educating researchers, practitioners, and students about the need for improved understanding of how users use search engines, and tools for achieving that understanding.&nbsp; The PI developed a course on empirical methods for computer science for students at the University of Delaware as well as a 3-hour presentation on statistical methods for better understanding search system effectiveness for researchers and practitioners.&nbsp; The PI gave these courses several times over the course of the award, sometimes invited to an event or company specifically to speak about it.</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/14/2021<br>      Modified by: Benjamin&nbsp;Carterette</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This award was used to study how people use search systems to complete tasks, and how to use the learnings from those studies to improve search systems in targeted, personalized ways.  For the first few years of the award, we focused on search in sessions.  A simple example of a task completed in a session is planning a trip: a person may make several searches, to find hotels, flights, attractions, and so on.  In such sessions, the user often learns things in the course of their searches, makes decisions, changes their mind, and generally evolves over time.  A search engine that can anticipate these changes may better help users.     To help study this, we started a cooperative competition, or "co-opetition", in which we provided a large dataset of user searches and invited academic and commercial research groups to try to engineer the best search engine for these types of user sessions.  It is called a "co-opetition" because after results are revealed, all groups are required to share how they solved the problem via published, freely-available papers.  This enables tech transfer from academic research to industry.  IBM and Microsoft were two of the commercial enterprises that participated in our co-opetition.     After several years of studying sessions, we transitioned to studying tasks more directly.  In collaboration with University College of London, Microsoft, and Google, we began another "co-opetition" for research groups to build search engines to help users complete tasks.  This ran for three years during the award.     In the final year of the award, the PI joined Spotify as a visiting research scientist.  Spotify provides search and recommendations for music and podcasts.  At Spotify the PI was able to participate in tech transfer from academia to industry, particularly learnings from the session and task co-opetitions described above.  Furthermore, Spotify has enormous logs of the search and consumption behavior of users, an invaluable tool in understanding how users use these systems and how to improve them.  We leveraged this data to develop new methods to rapidly prototype search and recommender systems offline.  Some of this work has been integrated into Spotifyâ€™s development workflows.     The work above resulted in dozens of papers published at top-tier venues in computer science.  The PI graduated five PhD students who were funded from the award.  One of these students was from the West African nation of Togo, a traditionally underrepresented group in computer science.  All five are now working in industrial settings in the US.     CAREER awards are also about education.  Part of the award period was devoted to educating researchers, practitioners, and students about the need for improved understanding of how users use search engines, and tools for achieving that understanding.  The PI developed a course on empirical methods for computer science for students at the University of Delaware as well as a 3-hour presentation on statistical methods for better understanding search system effectiveness for researchers and practitioners.  The PI gave these courses several times over the course of the award, sometimes invited to an event or company specifically to speak about it.          Last Modified: 01/14/2021       Submitted by: Benjamin Carterette]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
