<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DISSERTATION RESEARCH: Mechanisms of receiver psychology in acoustic communication</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>19502.00</AwardTotalIntnAmount>
<AwardAmount>19502</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08090500</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>IOS</Abbreviation>
<LongName>Division Of Integrative Organismal Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>emilia martins</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Humans and other animals often communicate acoustically in noisy social environments. These environments present serious challenges to effective communication when multiple individuals signal simultaneously. A fundamental goal of auditory neuroscience is to understand how nervous systems group together the different sounds produced by one source in the presence of multiple competing sources. This research investigates auditory grouping in an animal model that communicates acoustically in large social groups and has a unique auditory system. The work uses behavioral assays and neural recordings to study how anurans (frogs and toads) use frequency cues to group the discrete sound elements comprising communication signals. Preliminary studies suggested that use of frequency cues by anurans is supported by two mechanisms, one similar to that of mammals and birds and one resulting from the unique physiology of anuran inner ears. Further study will investigate these mechanisms at various levels of the anuran auditory system. It is expected that low levels of the auditory system will use mechanisms similar to those that have been observed in other animals, but that there will be two distinct variations, again reflecting the anuran ears' unique physiology. At higher levels of the auditory system, a new mechanism is expected to manifest which combines frequency cues with temporal cues to produce a neural "readout" of the perceptual state of the animal. This research will contribute to a broader and more general understanding of how auditory systems perceive acoustic communication signals in noisy environments. Such data are essential for understanding the potential diversity of ways that evolution may solve common problems in diverse groups of animals. This basic biological knowledge, in turn, could one day benefit people with impaired hearing. The project also integrates research with the training and teaching of undergraduate and graduate students and additionally will foster an international collaboration.</AbstractNarration>
<MinAmdLetterDate>06/21/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/21/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1311194</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Bee</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark A Bee</PI_FULL_NAME>
<EmailAddress>mbee@umn.edu</EmailAddress>
<PI_PHON>6126246749</PI_PHON>
<NSF_ID>000292566</NSF_ID>
<StartDate>06/21/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Katrina</FirstName>
<LastName>Schrode</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katrina M Schrode</PI_FULL_NAME>
<EmailAddress>schro641@umn.edu</EmailAddress>
<PI_PHON>6126243769</PI_PHON>
<NSF_ID>000630816</NSF_ID>
<StartDate>06/21/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>St. Paul</CityName>
<StateCode>MN</StateCode>
<ZipCode>551086098</ZipCode>
<StreetAddress><![CDATA[1987 Upper Buford Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7659</Code>
<Text>Animal Behavior</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~19502</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>For many animals, acoustic communication occurs in large, and hence noisy, social groups (e.g., dawn choruses of songbirds, colonies of seabirds, choruses of insects and frogs). Detection and recognition of acoustic signals is particularly difficult when there are multiple signalers producing overlapping signals and generating high background noise levels. While many studies have investigated how animals encode acoustic stimuli under optimal (quiet) conditions, much less is known about how they do so in more realistic sonic environments. The&nbsp;<span style="text-decoration: underline;">broad aim</span>&nbsp;of the current project was to investigate neurosensory mechanisms that are important in signal reception in noisy acoustic environments. Two experiments were completed.</p> <p>The first experiment investigated &ldquo;auditory stream segregation,&rdquo; a process by which overlapping sounds are perceptually separated into distinct auditory objects that represent the original signals. Sounds that differ in some perceptually salient feature (e.g., frequency or timing) are usually segregated into different streams. This experiment tested whether treefrogs use frequency differences as a cue for segregating sounds into separate streams. In previous work, we tested female subjects by letting them choose between two synthetic calls that resembled the male&rsquo;s pulsatile mating call. Call #1 consisted of alternating groups of pulses that differed in frequency (e.g., ABABABA) and was longer than Call #2, in which all pulses had the same frequency (e.g., AAAAA). Females prefer longer calls and discriminate against calls missing pulses (e.g., A_A_A).&nbsp; Under some conditions, such as when the frequency difference between the A and B pulses was sufficiently large, females discriminated against the longer Call #1. These results were consistent with a stream segregation interpretation. However, there was a potential confound in that treefrogs may have found certain frequencies inherently unattractive. A new study funded by this award tested the hypothesis that inherent frequency biases explain the previous data on stream segregation. Subjects were given a choice between a longer Call #1 in which frequency of the pulses did not differ (e.g., BBBBBBB) and a shorter Call #2 identical to that used in the earlier experiment (e.g., AAAAA). Given the known preference of females for longer calls, we predicted they would prefer the longer Call #1 over the shorter Call #2, <em>unless</em> they had inherent biases against pulses at frequency B. Indeed, we found that for low frequencies, the frequency bias hypothesis was supported, allowing us to qualify our interpretation of stream segregation. At high frequencies, however, we were able to reject the frequency bias hypothesis and thus confirm an interpretation of our earlier results based on stream segregation. Because low and high frequencies are processed by different sensory organs in the frog inner ear, our data reveal that the frog auditory system uses information encoded by the two organs differently when processing sound mixtures.</p> <p>&nbsp;In the second experiment, we studied &ldquo;dip listening,&rdquo; a process auditory systems use to detect signals in noisy environments. The higher the amplitude of the background noise, the harder it is to detect specific sounds. However, natural noise backgrounds fluctuate in time, and thus have many &ldquo;dips&rdquo; and &ldquo;peaks&rdquo; in amplitude. In humans, these amplitude fluctuations can be beneficial, because listeners can catch &ldquo;acoustic glimpses&rdquo; when the amplitude of background noise momentarily dips in level. Previous experiments in the lab showed that female treefrogs are also better at detecting and responding to mating calls in background noise when the amplitude of the noise fluctuates compared to when it does not (even though the long-term average...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ For many animals, acoustic communication occurs in large, and hence noisy, social groups (e.g., dawn choruses of songbirds, colonies of seabirds, choruses of insects and frogs). Detection and recognition of acoustic signals is particularly difficult when there are multiple signalers producing overlapping signals and generating high background noise levels. While many studies have investigated how animals encode acoustic stimuli under optimal (quiet) conditions, much less is known about how they do so in more realistic sonic environments. The broad aim of the current project was to investigate neurosensory mechanisms that are important in signal reception in noisy acoustic environments. Two experiments were completed.  The first experiment investigated "auditory stream segregation," a process by which overlapping sounds are perceptually separated into distinct auditory objects that represent the original signals. Sounds that differ in some perceptually salient feature (e.g., frequency or timing) are usually segregated into different streams. This experiment tested whether treefrogs use frequency differences as a cue for segregating sounds into separate streams. In previous work, we tested female subjects by letting them choose between two synthetic calls that resembled the maleÃ†s pulsatile mating call. Call #1 consisted of alternating groups of pulses that differed in frequency (e.g., ABABABA) and was longer than Call #2, in which all pulses had the same frequency (e.g., AAAAA). Females prefer longer calls and discriminate against calls missing pulses (e.g., A_A_A).  Under some conditions, such as when the frequency difference between the A and B pulses was sufficiently large, females discriminated against the longer Call #1. These results were consistent with a stream segregation interpretation. However, there was a potential confound in that treefrogs may have found certain frequencies inherently unattractive. A new study funded by this award tested the hypothesis that inherent frequency biases explain the previous data on stream segregation. Subjects were given a choice between a longer Call #1 in which frequency of the pulses did not differ (e.g., BBBBBBB) and a shorter Call #2 identical to that used in the earlier experiment (e.g., AAAAA). Given the known preference of females for longer calls, we predicted they would prefer the longer Call #1 over the shorter Call #2, unless they had inherent biases against pulses at frequency B. Indeed, we found that for low frequencies, the frequency bias hypothesis was supported, allowing us to qualify our interpretation of stream segregation. At high frequencies, however, we were able to reject the frequency bias hypothesis and thus confirm an interpretation of our earlier results based on stream segregation. Because low and high frequencies are processed by different sensory organs in the frog inner ear, our data reveal that the frog auditory system uses information encoded by the two organs differently when processing sound mixtures.   In the second experiment, we studied "dip listening," a process auditory systems use to detect signals in noisy environments. The higher the amplitude of the background noise, the harder it is to detect specific sounds. However, natural noise backgrounds fluctuate in time, and thus have many "dips" and "peaks" in amplitude. In humans, these amplitude fluctuations can be beneficial, because listeners can catch "acoustic glimpses" when the amplitude of background noise momentarily dips in level. Previous experiments in the lab showed that female treefrogs are also better at detecting and responding to mating calls in background noise when the amplitude of the noise fluctuates compared to when it does not (even though the long-term average level remains constant in both conditions). In a new study funded by this award, we tested the hypothesis that signals are more easily detected by the auditory system during "dips" in amplitude versus an alternative "...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
