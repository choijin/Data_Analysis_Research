<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Collaborative: Language-Action Causal Graphs for Trustworthiness Attribution in Computer-Mediated Communication</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>80000.00</AwardTotalIntnAmount>
<AwardAmount>80000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ralph Wachter</SignBlockName>
<PO_EMAI>rwachter@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This collaborative research between Florida State University and Cornell University is to identify language-action features from text-based messages that can be used to dynamically infer a social actor's perceived trustworthiness. The team will investigate using optimal analysis techniques to calibrate trustworthiness reasoning, which can be used to computationally model actors' deceptive behaviors in cyber space and to infer actors' intent based on their words and actions.&lt;br/&gt;&lt;br/&gt;This research will have a transformative impact in understanding the dynamics of trusting relationships through observing language-action features and psychosocial trustworthiness attribution mechanisms. This study serves as a precursor to a socio-technical schema that will facilitate national security and data protection for the general populace while also protecting the individual's right to privacy. This study will contribute to the science of cyber-security, and will help the cyber-security community to understand and enable trustworthy communication and collaborative information behavior among computer-mediated groups in a systematic way.</AbstractNarration>
<MinAmdLetterDate>08/26/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1347120</AwardID>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Hancock</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeffrey T Hancock</PI_FULL_NAME>
<EmailAddress>hancockj@stanford.edu</EmailAddress>
<PI_PHON>6507231941</PI_PHON>
<NSF_ID>000156585</NSF_ID>
<StartDate>08/26/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148534203</ZipCode>
<StreetAddress><![CDATA[320 Kennedy Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~80000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Cyber phenomena have resulted in new emergent behaviors that are reflected in complex interactions among computers, cyber&shy;physical devices, and humans. While the vast majority of packet switching and information exchange are done via computers, human factors are perhaps the most critical and yet most difficult to model in the cybersecurity domain. The threats to information assets&mdash;as well as threats to individual privacy&mdash;are multiplied as a result of decisions and choices made by humans in cyber operations. Cyber threats exist in diverse scenarios, ranging from hacking and online deception, identity theft, fraud, to malicious insider threats.</p> <p>Any systematic approach to understanding these threats must model human factors, and human factors in online contexts almost always involve the exchange of text. In a primarily linguistic environment such as cyberspace, words are the primary signal for both intent and action. The words exchanged in social interactions and other forms of human communication can often reflect intention to act and subtle changes in intent. By observing human behavior through language, we are able to conceptually and computationally detect changes in motivation and communicative intent. The patterns that emerge are recognizable. There are patterns that signal deceptive behavior, just as there are patterns that signal trustworthy behavior. This research demonstrates our ability to identify language&shy;action cues and features in text&shy;based messages that can be used to dynamically infer a social actor&rsquo;s perceived trustworthiness.</p> <p>Intellectual Merit: Based on social science theories on trust and attribution, we are able to identify language&shy;action cues that predict deceptiveness and trustworthiness, and which can be used in support vector machines to computationally infer the deception and trustworthiness of interacting actors in an online environment. Our approach is to first process and extract language&shy;action cues based on outlier behavior scenarios&mdash;data collected from an online game experiment&mdash;to establish attribution models of trustworthiness. A key novelty of our approach is that context&shy;sensitive semantic aspects of words and resulting actions will be inferred jointly, along with causal inference of motives and other cognitive factors. The data collected for establishing the support vector machines and decision tree learning approach are language&shy;action cues. The language &shy;action cues feed a causality reasoning system where the trustworthiness of the social actor is regularly analyzed and updated in a recursive inference framework. The probabilities are then used in a support vector machines to update the deceptiveness and trustworthiness of the focal actor within the inference framework. A key novelty of this approach is that the causality reasoning is guided by social science theories on trust and attribution, and users&rsquo; interactive communication data is the primary data source which indicates communicators&rsquo; intent and motivation.</p> <p>Broader Impacts: This research has a transformative impact in understanding the dynamics of trusting relationships through language&shy;action cues and psychosocial trustworthiness attribution mechanisms. This study serves as a precursor to a sociotechnical schema that will facilitate national security and data protection for the general populace while also protecting the individuals&rsquo; right to privacy.&nbsp;</p><br> <p>            Last Modified: 01/13/2016<br>      Modified by: Jeffrey&nbsp;T&nbsp;Hancock</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Cyber phenomena have resulted in new emergent behaviors that are reflected in complex interactions among computers, cyber&shy;physical devices, and humans. While the vast majority of packet switching and information exchange are done via computers, human factors are perhaps the most critical and yet most difficult to model in the cybersecurity domain. The threats to information assets&mdash;as well as threats to individual privacy&mdash;are multiplied as a result of decisions and choices made by humans in cyber operations. Cyber threats exist in diverse scenarios, ranging from hacking and online deception, identity theft, fraud, to malicious insider threats.  Any systematic approach to understanding these threats must model human factors, and human factors in online contexts almost always involve the exchange of text. In a primarily linguistic environment such as cyberspace, words are the primary signal for both intent and action. The words exchanged in social interactions and other forms of human communication can often reflect intention to act and subtle changes in intent. By observing human behavior through language, we are able to conceptually and computationally detect changes in motivation and communicative intent. The patterns that emerge are recognizable. There are patterns that signal deceptive behavior, just as there are patterns that signal trustworthy behavior. This research demonstrates our ability to identify language&shy;action cues and features in text&shy;based messages that can be used to dynamically infer a social actorÆs perceived trustworthiness.  Intellectual Merit: Based on social science theories on trust and attribution, we are able to identify language&shy;action cues that predict deceptiveness and trustworthiness, and which can be used in support vector machines to computationally infer the deception and trustworthiness of interacting actors in an online environment. Our approach is to first process and extract language&shy;action cues based on outlier behavior scenarios&mdash;data collected from an online game experiment&mdash;to establish attribution models of trustworthiness. A key novelty of our approach is that context&shy;sensitive semantic aspects of words and resulting actions will be inferred jointly, along with causal inference of motives and other cognitive factors. The data collected for establishing the support vector machines and decision tree learning approach are language&shy;action cues. The language &shy;action cues feed a causality reasoning system where the trustworthiness of the social actor is regularly analyzed and updated in a recursive inference framework. The probabilities are then used in a support vector machines to update the deceptiveness and trustworthiness of the focal actor within the inference framework. A key novelty of this approach is that the causality reasoning is guided by social science theories on trust and attribution, and usersÆ interactive communication data is the primary data source which indicates communicatorsÆ intent and motivation.  Broader Impacts: This research has a transformative impact in understanding the dynamics of trusting relationships through language&shy;action cues and psychosocial trustworthiness attribution mechanisms. This study serves as a precursor to a sociotechnical schema that will facilitate national security and data protection for the general populace while also protecting the individualsÆ right to privacy.        Last Modified: 01/13/2016       Submitted by: Jeffrey T Hancock]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
