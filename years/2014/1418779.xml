<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Multiscale Basis Dictionaries and Best Bases for Data Analysis on Graphs and Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>475000.00</AwardTotalIntnAmount>
<AwardAmount>475000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In recent years, the advent of new sensors, measurement technologies, and social network infrastructure has provided huge opportunities to visualize complicated interconnected network structures and record data of interest at various locations in such networks. Consequently, there is an explosion of interest and demand to analyze such data and make inferences, predictions, and diagnostics. Examples of such data include, but are not limited to: biology and medicine (e.g., blood flow rates in a network of blood vessels); computer and social sciences (e.g., information flows in social networks); electrical engineering (e.g., sensor networks); hydrology and geology (e.g., river flow measurements in a ramified river network); and civil engineering (e.g., traffic flow on a road network). The investigator and his team will develop mathematical and computational tools referred to as "multiscale basis dictionaries" on a given graph, which will have a positive impact in solving practical data analysis problems on graphs and networks in diverse fields as listed above. In particular, these dictionaries will be able to capture subtle features discriminating anomalous events from normal events on graphs, which may shed light on underlying causes of such anomalies. Students engaged in this project will be trained to be the next generation of interdisciplinary scientists who have deep knowledge in one area yet have open mind to the other areas and try to actively seek collaborations with domain experts. Such an attitude and a perspective will be indispensable for their future career, either in academia or in industry.&lt;br/&gt;&lt;br/&gt;The goal of this project is to develop above-mentioned multiscale basis dictionaries and best bases selected from such dictionaries for graphs and networks, and demonstrate the usefulness by examining their performance on a variety of data analysis tasks on graphs and networks such as compression, denoising, semi-supervised learning, and anomaly detection. Mathematical and computational tools for analyzing such datasets, particularly for those on directed graphs, have not been well developed. For more conventional data supported on simple Euclidean domains and data sampled on regular lattices, harmonic analysis tools such as Fourier and wavelet transforms as well as multiscale basis dictionaries, e.g., wavelet packets and local trigonometric transforms, have a proven track record of success. This project can be viewed as the continuing effort of the investigator to transfer and extend these computational harmonic analysis tools from the realm of regular lattices and simple Euclidean domains to more general graph domains. The multiscale basis dictionaries for graphs including a complete Haar-Walsh basis dictionary will certainly enrich the current collection of data analysis tools on such domains because these dictionaries contain a huge number of possible bases from which one can quickly select a basis most suitable for a given task via the best-basis selection algorithm. In particular, any addition of mathematical and computational tools for data analysis on directed graphs is well rewarded since there are comparably few tools available despite their practical importance. This is partly because so many classes of directed graphs exist, and consequently, there has been confusion over the definitions of graph Laplacian matrices. Instead, this project provides a new viewpoint: on a directed graph, the connectivity between any two vertices are not a local concept; rather it is a global concept. Finding a shortest path connecting a given pair of vertices provides critical information on a directed graph. To utilize such information fully, spectral analysis of the distance matrices and the associated integral operators on a directed graph is performed using the singular value decomposition instead of analyzing the graph Laplacians using the eigendecomposition.</AbstractNarration>
<MinAmdLetterDate>07/26/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1418779</AwardID>
<Investigator>
<FirstName>Naoki</FirstName>
<LastName>Saito</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Naoki Saito</PI_FULL_NAME>
<EmailAddress>saito@math.ucdavis.edu</EmailAddress>
<PI_PHON>5307542121</PI_PHON>
<NSF_ID>000111847</NSF_ID>
<StartDate>07/26/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Davis</Name>
<CityName>Davis</CityName>
<ZipCode>956186134</ZipCode>
<PhoneNumber>5307547700</PhoneNumber>
<StreetAddress>OR/Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1850 Research Park Dr., Ste 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>047120084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, DAVIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Davis]]></Name>
<CityName>Davis</CityName>
<StateCode>CA</StateCode>
<ZipCode>956168633</ZipCode>
<StreetAddress><![CDATA[One Shields Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~113403</FUND_OBLG>
<FUND_OBLG>2015~177361</FUND_OBLG>
<FUND_OBLG>2016~184236</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In recent years, the advent of new sensors, measurement technologies, and social network infrastructure has provided many research opportunities for recording data of interest at various locations in complex networks, visualizing and analyzing complicated interconnected network structures, and making inferences and diagnostics. Network-based problems are ubiquitous: They appear in biology and medicine; computer science; electrical engineering; hydrology and geology; and civil engineering, to name just a few. Consequently, there is an explosion of interest and demand to analyze data sampled from irregular grids, graphs, and networks.<br /><br />What about the mathematical and computational tools for analyzing such datasets? Time-honored harmonic analysis tools such as Fourier and wavelet transforms have been the "crown jewels" for examining regularly-sampled data. These tools have a wide range of applications, e.g., data compression, image analysis, and statistical signal processing. However, these conventional tools cannot directly handle datasets recorded on general graphs and networks: a fundamental difficulty is a lack of a proper notion of <em>frequency</em> on general graphs.<br /><br />During this NSF grant period, we have developed and refined the <em>Hierarchical Graph Laplacian Eigen Transform</em> (HGLET) and the<em> Generalized Haar-Walsh Transform</em> (GHWT). These transforms generate a redundant collection of basis vectors called<em> basis dictionaries</em>, consisting of a large number of orthonormal bases through which one can view an input signal defined on the graph nodes from many different perspectives. The fast best basis algorithm can select an orthonormal basis from these dictionaries that is most suitable (or offers the "<em>best view</em>") for a given task, such as compression and classification. In the graph setting, HGLET and GHWT are true generalizations of classical hierarchical block discrete cosine transform and Haar-Walsh wavelet packets, respectively. <br /><br />One of the important emerging applications of these newly developed tools is analysis of matrix data. For example, in a <em>term-document matrix</em>, the rows correspond to words and the columns correspond to documents, and the <em>ij</em>-th entry of such a matrix is typically the (relative) frequency with which word <em>i</em> appears in document <em>j</em>. In the case that the documents are journal articles from different fields, one would expect the prevalence and absence of certain words to be relatively consistent across documents from within each field. Such matrices are quite different from usual photographic images. In fact, they are often more like shuffled and permuted images, possessing <em>no spatial smoothness or coherency</em> in general. Yet, those rows and columns are interrelated, and thus the rows of the matrix can tell us about the underlying structure of the columns, and vice versa. But how can we do that?&nbsp; Our tools now come to the rescue: these allow us to discover, learn, and exploit hidden dependency and geometric structure in the matrix data in an innovative way.<br />Here is a real example: the term-document matrix consisting of 1042 columns representing documents obtained from the <em>Science News</em> website and 1153 rows representing preselected most relevant words. Each document belongs to one of the eight categories ranging from Anthropology to Physics. Fig.1 shows that both words and documents are embedded in the same Euclidean space using the spectral co-clustering. At the left side of the boomerang shape cluster, a majority of documents are of Astronomy and the related words (e.g., <span style="text-decoration: underline;">extrasolar</span>) are clustered closely to those documents while the right side of the boomerang mainly consists of Medical Science documents and the related words (e.g., <span style="text-decoration: underline;">tamoxifen</span>). Fig.2 and 3 compare the original matrix and the reordered matrix using one of our algorithms; the total number of orthonormal bases searched via their algorithm exceeds 10<sup>370</sup>. It is reassuring to see that the resulting best basis does in fact sparsify the input matrix nicely. The resulting best basis not only sparsifies the input matrix but also provides us insights on the underlying matrix data. For example, the best basis vectors corresponding to the important coefficients have their support on the 51 documents with 48 belonging to Astronomy. The titles of the remaining three turn out to be the following:</p> <ul> <li>"<em>Old Glory, New Glory: The Star-Spangled Banner gets some tender loving care</em>" (Anthropology; on the preservation of the Star-Spangled Banner (flag) using the space-age technology)</li> <li>"<em>Snouts: A star is born in a very odd way</em>" (Life Sciences; on star-nosed moles)</li> <li>"<em>Gravity tugs at the center of a priority battle</em>" (Math/CS; on the priority war on the discovery of gravity between Newton, Halley, and Hooke)</li> </ul> <p>These three articles are picked out along with the Astronomy articles because they contain some astronomical keywords as one can see.<br /><br />These results are based on the examination of the particular best basis vectors and the corresponding coefficients at one intermediate scale.<br />We believe that our approach can further advance the state of clustering and classification of documents by linking information at multiple scales. <br />We envision that these tools will be useful for finding "<em>patterns</em>" hidden in unorganized massive datasets of various kinds.</p><br> <p>            Last Modified: 09/23/2018<br>      Modified by: Naoki&nbsp;Saito</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736758286_SNmatpart--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736758286_SNmatpart--rgov-800width.jpg" title="Fig. 3. The GHWT algorithm reorders the rows and columns of the Science News matrix"><img src="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736758286_SNmatpart--rgov-66x44.jpg" alt="Fig. 3. The GHWT algorithm reorders the rows and columns of the Science News matrix"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our GHWT algorithm extended for matrix data reordered the rows and the columns of the Science News matrix in order to reveals the underlying dependency between rows (words) and columns (documents), at the same time, sparsifies the matrix entries.</div> <div class="imageCredit">Naoki Saito</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Naoki&nbsp;Saito</div> <div class="imageTitle">Fig. 3. The GHWT algorithm reorders the rows and columns of the Science News matrix</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736120863_dhillon_joint3d--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736120863_dhillon_joint3d--rgov-800width.jpg" title="Fig. 1. Embedding of the Science News matrix data (1153 &times; 1042)"><img src="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736120863_dhillon_joint3d--rgov-66x44.jpg" alt="Fig. 1. Embedding of the Science News matrix data (1153 &times; 1042)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Words/documents simultaenously embedded in the 2nd, 3rd, and 4th bipartite graph Laplacian eigenvectors of the Science News database</div> <div class="imageCredit">Naoki Saito</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Naoki&nbsp;Saito</div> <div class="imageTitle">Fig. 1. Embedding of the Science News matrix data (1153 Ã— 1042)</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736387918_SNmat--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736387918_SNmat--rgov-800width.jpg" title="Fig. 2. Original Science News Term-Document Matrix"><img src="/por/images/Reports/POR/2018/1418779/1418779_10323925_1537736387918_SNmat--rgov-66x44.jpg" alt="Fig. 2. Original Science News Term-Document Matrix"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The sparsity pattern of the original Science News term-document matrix is shown. Blue dots indicate nonzero entries of this matrix.</div> <div class="imageCredit">Naoki Saito</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Naoki&nbsp;Saito</div> <div class="imageTitle">Fig. 2. Original Science News Term-Document Matrix</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In recent years, the advent of new sensors, measurement technologies, and social network infrastructure has provided many research opportunities for recording data of interest at various locations in complex networks, visualizing and analyzing complicated interconnected network structures, and making inferences and diagnostics. Network-based problems are ubiquitous: They appear in biology and medicine; computer science; electrical engineering; hydrology and geology; and civil engineering, to name just a few. Consequently, there is an explosion of interest and demand to analyze data sampled from irregular grids, graphs, and networks.  What about the mathematical and computational tools for analyzing such datasets? Time-honored harmonic analysis tools such as Fourier and wavelet transforms have been the "crown jewels" for examining regularly-sampled data. These tools have a wide range of applications, e.g., data compression, image analysis, and statistical signal processing. However, these conventional tools cannot directly handle datasets recorded on general graphs and networks: a fundamental difficulty is a lack of a proper notion of frequency on general graphs.  During this NSF grant period, we have developed and refined the Hierarchical Graph Laplacian Eigen Transform (HGLET) and the Generalized Haar-Walsh Transform (GHWT). These transforms generate a redundant collection of basis vectors called basis dictionaries, consisting of a large number of orthonormal bases through which one can view an input signal defined on the graph nodes from many different perspectives. The fast best basis algorithm can select an orthonormal basis from these dictionaries that is most suitable (or offers the "best view") for a given task, such as compression and classification. In the graph setting, HGLET and GHWT are true generalizations of classical hierarchical block discrete cosine transform and Haar-Walsh wavelet packets, respectively.   One of the important emerging applications of these newly developed tools is analysis of matrix data. For example, in a term-document matrix, the rows correspond to words and the columns correspond to documents, and the ij-th entry of such a matrix is typically the (relative) frequency with which word i appears in document j. In the case that the documents are journal articles from different fields, one would expect the prevalence and absence of certain words to be relatively consistent across documents from within each field. Such matrices are quite different from usual photographic images. In fact, they are often more like shuffled and permuted images, possessing no spatial smoothness or coherency in general. Yet, those rows and columns are interrelated, and thus the rows of the matrix can tell us about the underlying structure of the columns, and vice versa. But how can we do that?  Our tools now come to the rescue: these allow us to discover, learn, and exploit hidden dependency and geometric structure in the matrix data in an innovative way. Here is a real example: the term-document matrix consisting of 1042 columns representing documents obtained from the Science News website and 1153 rows representing preselected most relevant words. Each document belongs to one of the eight categories ranging from Anthropology to Physics. Fig.1 shows that both words and documents are embedded in the same Euclidean space using the spectral co-clustering. At the left side of the boomerang shape cluster, a majority of documents are of Astronomy and the related words (e.g., extrasolar) are clustered closely to those documents while the right side of the boomerang mainly consists of Medical Science documents and the related words (e.g., tamoxifen). Fig.2 and 3 compare the original matrix and the reordered matrix using one of our algorithms; the total number of orthonormal bases searched via their algorithm exceeds 10370. It is reassuring to see that the resulting best basis does in fact sparsify the input matrix nicely. The resulting best basis not only sparsifies the input matrix but also provides us insights on the underlying matrix data. For example, the best basis vectors corresponding to the important coefficients have their support on the 51 documents with 48 belonging to Astronomy. The titles of the remaining three turn out to be the following:  "Old Glory, New Glory: The Star-Spangled Banner gets some tender loving care" (Anthropology; on the preservation of the Star-Spangled Banner (flag) using the space-age technology) "Snouts: A star is born in a very odd way" (Life Sciences; on star-nosed moles) "Gravity tugs at the center of a priority battle" (Math/CS; on the priority war on the discovery of gravity between Newton, Halley, and Hooke)   These three articles are picked out along with the Astronomy articles because they contain some astronomical keywords as one can see.  These results are based on the examination of the particular best basis vectors and the corresponding coefficients at one intermediate scale. We believe that our approach can further advance the state of clustering and classification of documents by linking information at multiple scales.  We envision that these tools will be useful for finding "patterns" hidden in unorganized massive datasets of various kinds.       Last Modified: 09/23/2018       Submitted by: Naoki Saito]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
