<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Increasing the Effectiveness and Utilization of Data Structure Visualizations in Undergraduate Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2010</AwardEffectiveDate>
<AwardExpirationDate>01/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>74995.00</AwardTotalIntnAmount>
<AwardAmount>74995</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040200</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Tymann</SignBlockName>
<PO_EMAI>ptymann@nsf.gov</PO_EMAI>
<PO_PHON>7032922832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer Science (31)&lt;br/&gt;&lt;br/&gt;Software visualizations are recognized as valuable teaching and learning tools.  Prior NSF funding produced jGRASP, a software development environment that allows students to visualize their programs and data structures.  While jGRASP has been widely disseminated and has been met with a high degree of success, teachers do not use the data structure visualization features to their full potential.  Objectives of this project are to train teachers to use effective program visualization practices in the classroom and to develop a set of learning materials that integrate dynamic visualizations with appropriate teaching strategies.&lt;br/&gt;&lt;br/&gt;Two summer workshops are the primary strategy for developing materials and training faculty.  The first workshop is designed to develop data structure visualizations and make plans for participants to use the materials during the following academic year.  The second workshop is designed to refine materials and to train additional teachers.  Expected outcomes include learning resources, data structure visualizations and a diverse community of trained faculty from high schools, community colleges and universities.  &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/05/2010</MinAmdLetterDate>
<MaxAmdLetterDate>03/05/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0941862</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Cross</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME>II</PI_SUFX_NAME>
<PI_FULL_NAME>James H Cross</PI_FULL_NAME>
<EmailAddress>crossjh@auburn.edu</EmailAddress>
<PI_PHON>3348446315</PI_PHON>
<NSF_ID>000374056</NSF_ID>
<StartDate>03/05/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Theron</FirstName>
<LastName>Hendrix</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Theron D Hendrix</PI_FULL_NAME>
<EmailAddress>hendrtd@auburn.edu</EmailAddress>
<PI_PHON>3348446305</PI_PHON>
<NSF_ID>000350630</NSF_ID>
<StartDate>03/05/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Umphress</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>David A Umphress</PI_FULL_NAME>
<EmailAddress>umphress@eng.auburn.edu</EmailAddress>
<PI_PHON>3348446335</PI_PHON>
<NSF_ID>000185290</NSF_ID>
<StartDate>03/05/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Auburn University</Name>
<CityName>Auburn</CityName>
<ZipCode>368320001</ZipCode>
<PhoneNumber>3348444438</PhoneNumber>
<StreetAddress>VPRED, Research &amp; Innovation Ctr</StreetAddress>
<StreetAddress2><![CDATA[540 Devall Drive, Suite 200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<StateCode>AL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066470972</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AUBURN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>066470972</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Auburn University]]></Name>
<CityName>Auburn</CityName>
<StateCode>AL</StateCode>
<ZipCode>368320001</ZipCode>
<StreetAddress><![CDATA[VPRED, Research &amp; Innovation]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1536</Code>
<Text>S-STEM-Schlr Sci Tech Eng&amp;Math</Text>
</ProgramElement>
<ProgramElement>
<Code>7494</Code>
<Text>CCLI-Type 1 (Exploratory)</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0410</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>13XX</Code>
<Name>H-1B FUND, EHR, NSF</Name>
<APP_SYMB_ID>045176</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~74995</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>During the first year of the project, we developed and piloted a set of learning materials. These materials integrated the use of the software visualizations provided by jGRASP with our classroom instructional activities in CS 1 and CS 2. After the materials were vetted by our first workshop participants (see below), they were refined and then provided to those faculty for use in their own courses. Subsequently, these materials were integrated into tutorials that are publicly available on the jGRASP web site (www.jgrasp.org).</p> <p>Over the course of the project, we have conducted four faculty development workshops, as described in the annual reports.</p> <ul> <li>July 2011, "Teaching with Effective Data Structure Visualizations for Java," Auburn University, Auburn, AL. (Workshop participants were supported with project funds.)</li> <li>November 2012, "Using the New jGRASP Canvas of Dynamic Viewers for Program Understanding and Debugging in Java," CCSC Southeastern Conference, Southern Polytechnic University, Marietta, GA. (Workshop participants were not supported with project funds.)</li> <li>September 2013, "Using the New jGRASP Canvas of Dynamic Viewers for Program Understanding and Debugging in Java," CCSC Midwest Conference, University of Findlay, Findlay, OH. (Workshop participants were not supported with project funds.)</li> <li>March 2014, "Dynamic Program Visualizations for Java," SIGCSE 2014, Atlanta, GA. (Note that this workshop was beyond the funding period. However, we used materials developed during the project period, and NSF support was cited.)</li> </ul> <p>Each workshop focused on providing computing faculty with knowledge and experience in using effective software visualizations for Java as an integral part of their classroom instruction. We received valuable feedback from each workshop that informed the continued development of jGRASP and its visualizations.</p> <p>We disseminated the results of the project via the jGRASP website (www.jgrasp.org), conference publications, and a booth at the annual SIGCSE conference (2011, 2012, 2013, 2014).</p> <p>The two most significant results of this project are (1) a community of educators who perceive the software visualizations provided by jGRASP to be useful, and (2) students who perceive value from using these visualizations as part of their classroom experience.&nbsp;</p> <p>The 21 veteran CS1, CS2, and Algorithms faculty members who participated in the 2011 workshop were asked to respond to a survey instrument focused on the perceived efficacy of the software visualizations provided by jGRASP. &nbsp;The survey instrument consisted of sixteen items grouped into four evaluation categories (EC). EC1 &ndash; Successful integration of visualization and IDE; EC2 &ndash; Usability; EC3 &ndash; Suitability for use in courses; EC4 &ndash; Aid in student learning. &nbsp;The 21 faculty members were asked to respond to each item on a scale of 1 to 5, where 1 indicated that the respondent strongly disagreed with the statement and 5 indicated that the respondent strongly agreed with the statement. While it is significant that the results were extremely positive across all evaluation question categories, it is particularly important to examine the responses that correspond to the effect on student learning (EC4). &nbsp;Item 12: jGRASP can positively affect the students&rsquo; knowledge, skills, and behavior. Mean = 4.62; Item 13: Students can acquire additional programming knowledge by using jGRASP (e.g., inheritance, data structure implementation). Mean = 4.43; Item 14: Students can acquire additional programming skills by using jGRASP (e.g., debugging, code reading). Mean = 4.48; Item 15: When appropriate, students will use visualizations in their approach to solving problems. Mean = 4.05; Item 16: When students use visualizations in their approach to solving problems, they can inherently gain a deeper understand...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ During the first year of the project, we developed and piloted a set of learning materials. These materials integrated the use of the software visualizations provided by jGRASP with our classroom instructional activities in CS 1 and CS 2. After the materials were vetted by our first workshop participants (see below), they were refined and then provided to those faculty for use in their own courses. Subsequently, these materials were integrated into tutorials that are publicly available on the jGRASP web site (www.jgrasp.org).  Over the course of the project, we have conducted four faculty development workshops, as described in the annual reports.  July 2011, "Teaching with Effective Data Structure Visualizations for Java," Auburn University, Auburn, AL. (Workshop participants were supported with project funds.) November 2012, "Using the New jGRASP Canvas of Dynamic Viewers for Program Understanding and Debugging in Java," CCSC Southeastern Conference, Southern Polytechnic University, Marietta, GA. (Workshop participants were not supported with project funds.) September 2013, "Using the New jGRASP Canvas of Dynamic Viewers for Program Understanding and Debugging in Java," CCSC Midwest Conference, University of Findlay, Findlay, OH. (Workshop participants were not supported with project funds.) March 2014, "Dynamic Program Visualizations for Java," SIGCSE 2014, Atlanta, GA. (Note that this workshop was beyond the funding period. However, we used materials developed during the project period, and NSF support was cited.)   Each workshop focused on providing computing faculty with knowledge and experience in using effective software visualizations for Java as an integral part of their classroom instruction. We received valuable feedback from each workshop that informed the continued development of jGRASP and its visualizations.  We disseminated the results of the project via the jGRASP website (www.jgrasp.org), conference publications, and a booth at the annual SIGCSE conference (2011, 2012, 2013, 2014).  The two most significant results of this project are (1) a community of educators who perceive the software visualizations provided by jGRASP to be useful, and (2) students who perceive value from using these visualizations as part of their classroom experience.   The 21 veteran CS1, CS2, and Algorithms faculty members who participated in the 2011 workshop were asked to respond to a survey instrument focused on the perceived efficacy of the software visualizations provided by jGRASP.  The survey instrument consisted of sixteen items grouped into four evaluation categories (EC). EC1 &ndash; Successful integration of visualization and IDE; EC2 &ndash; Usability; EC3 &ndash; Suitability for use in courses; EC4 &ndash; Aid in student learning.  The 21 faculty members were asked to respond to each item on a scale of 1 to 5, where 1 indicated that the respondent strongly disagreed with the statement and 5 indicated that the respondent strongly agreed with the statement. While it is significant that the results were extremely positive across all evaluation question categories, it is particularly important to examine the responses that correspond to the effect on student learning (EC4).  Item 12: jGRASP can positively affect the studentsÃ† knowledge, skills, and behavior. Mean = 4.62; Item 13: Students can acquire additional programming knowledge by using jGRASP (e.g., inheritance, data structure implementation). Mean = 4.43; Item 14: Students can acquire additional programming skills by using jGRASP (e.g., debugging, code reading). Mean = 4.48; Item 15: When appropriate, students will use visualizations in their approach to solving problems. Mean = 4.05; Item 16: When students use visualizations in their approach to solving problems, they can inherently gain a deeper understanding of the problem. Mean = 4.57. The faculty responding to the survey clearly believed that the visualizations in jGRASP could positively affect student learning. ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
