<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DIP: Collaborative Research: Mixed-Reality Labs: Integrating Sensors and Simulations to Improve Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2011</AwardEffectiveDate>
<AwardExpirationDate>09/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>391435.00</AwardTotalIntnAmount>
<AwardAmount>391435</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kevin Lee</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This collaborative project is investigating the characteristics of a mixed-reality learning environment that combines the rich context and multi-sensory experiences of a physical lab with the interactive simulations of a virtual lab. The hybrid environment integrates sensors and simulations to bring out the advantages of each setting in a complementary way. The research team is developing four such mixed-reality laboratory experiences for secondary school level chemistry and physics courses and studying student learning in these contexts. Two of the activities use an integration strategy in which data acquired in real time from a physical experiment are used to control a virtual experiment. The advantage of this coupling is that abstract concepts or invisible processes can be visualized on the computer screen while the physical experiment is underway. Whenever the learner's hands-on interaction with the physical experiments changes the sensor measurement, the visualization in the virtual experiment responds accordingly, creating an intimate link between the two worlds. The other integration strategy uses physical and virtual experiments in parallel, challenging the student to match the results measured by the sensors and the results computed by the simulations. The learning potential in this configuration stems from the ability to go back and forth between both worlds, adjusting the virtual experiment to match the physical experiment and then adjusting the physical experiment to test the fidelity of the virtual experiment. Implementations of the four activities in eight classrooms are being compared to classes covering similar content. The intellectual merit of this project lies in its investigation of the potential of cyberlearning technologies to transform inquiry in the lab. In addition, the project brings to bear the expertise of a recognized team of researchers. The project is exercising its broader impacts through its identification of a new instructional approach to STEM education. The combination of physical and virtual labs carries the potential for broad utility, with the insights and examples developed by this project potentially applicable throughout STEM education. In fact, because all of the project software is open source and the materials made available freely from the project's website, the only expenses to schools are for the sensors. A key design criterion is that all project software is compatible with sensors from multiple vendors so that schools are not limited in their choices.</AbstractNarration>
<MinAmdLetterDate>09/01/2011</MinAmdLetterDate>
<MaxAmdLetterDate>09/01/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1123868</AwardID>
<Investigator>
<FirstName>Jennifer</FirstName>
<LastName>Chiu</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jennifer L Chiu</PI_FULL_NAME>
<EmailAddress>jlchiu@virginia.edu</EmailAddress>
<PI_PHON>6505759848</PI_PHON>
<NSF_ID>000577296</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>065391526</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RECTOR &amp; VISITORS OF THE UNIVERSITY OF VIRGINIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>065391526</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Virginia Main Campus]]></Name>
<CityName/>
<StateCode>VA</StateCode>
<ZipCode>229044195</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8842</Code>
<Text>Design and Implementation Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~391435</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>This project developed and tested a novel class of mixed-reality technologies to support science learning. Leveraging existing software and probeware widely used in schools, this project created mixed-reality technologies that blend real and virtual experiences into a single activity and provided a foundation for a genre of applications with unprecedented learning opportunities.</p> <p><strong>Intellectual Merit: </strong>One of the reasons that science is difficult for students is because many scientific phenomena are invisible to the naked eye. To help students see science concepts in action in the real world, researchers at the Concord Consortium and the University of Virginia developed mixed-reality technologies that augment hands-on laboratory activities with sensor-driven computer simulations. Specifically, this grant created and tested the Frame, a novel augmented virtual technology that uses physical interactions with everyday objects to control a molecular simulation. The Frame differs from previous learning technologies in how it enables learning in classroom settings. Instead of using a glowball, mouse, or touch-screen interface, the Frame physically augments virtual phenomena by using multiple fast-response sensors that constantly collect and send data to a simulation to change its parameters. With the Frame, students control simulations with everyday objects that directly impact the virtual world. Students can warm an edge of a tablet computer to &ldquo;transfer&rdquo; heat into the virtual gas. Or they can push a real spring visually attached to a virtual piston to &ldquo;compress&rdquo; the gas. Or they can use a plunger to &ldquo;inject&rdquo; molecules into a virtual chamber. In this way, the technology creates a unique experience as if students could directly manipulate molecules&mdash;an experience that is only possible in research labs with advanced nanotechnology instruments.</p> <p>To test the effectiveness of these mixed-reality activities, this project involved over 1,000 middle and high school students in 50 classes with 9 teachers across six schools in Massachusetts and Virginia, as well as two undergraduate clinical studies. Results demonstrated learning gains for all students, and quasi-experimental studies demonstrated benefits of mixed-reality labs compared to sensor-based physical labs. An overwhelming majority of students found mixed-reality labs helpful for learning and preferred mixed-reality activities to purely virtual approaches.&nbsp;</p> <p><strong>Broader impacts</strong>. Results from our program of research add to the literature on mixed-reality environments as there are very few, if any, studies that use sensor-augmented virtual technologies in authentic classrooms. Findings help refine our knowledge about the relative contribution of physical augmentation in classroom contexts and contribute to a very small set of research that compares mixed-reality or embedded learning technologies to simulations or physical labs. The project&rsquo;s exploratory research provides the basis for the development of many more mixed-reality activities. Although the project uses sophisticated software, the simulations are open source and freely available on the project website. Sensors were specifically chosen to take advantage of equipment that many schools already have and use, so even the most cash-strapped schools can have access to these technologies.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/18/2015<br>      Modified by: Jennifer&nbsp;L&nbsp;Chiu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class=...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    This project developed and tested a novel class of mixed-reality technologies to support science learning. Leveraging existing software and probeware widely used in schools, this project created mixed-reality technologies that blend real and virtual experiences into a single activity and provided a foundation for a genre of applications with unprecedented learning opportunities.  Intellectual Merit: One of the reasons that science is difficult for students is because many scientific phenomena are invisible to the naked eye. To help students see science concepts in action in the real world, researchers at the Concord Consortium and the University of Virginia developed mixed-reality technologies that augment hands-on laboratory activities with sensor-driven computer simulations. Specifically, this grant created and tested the Frame, a novel augmented virtual technology that uses physical interactions with everyday objects to control a molecular simulation. The Frame differs from previous learning technologies in how it enables learning in classroom settings. Instead of using a glowball, mouse, or touch-screen interface, the Frame physically augments virtual phenomena by using multiple fast-response sensors that constantly collect and send data to a simulation to change its parameters. With the Frame, students control simulations with everyday objects that directly impact the virtual world. Students can warm an edge of a tablet computer to "transfer" heat into the virtual gas. Or they can push a real spring visually attached to a virtual piston to "compress" the gas. Or they can use a plunger to "inject" molecules into a virtual chamber. In this way, the technology creates a unique experience as if students could directly manipulate molecules&mdash;an experience that is only possible in research labs with advanced nanotechnology instruments.  To test the effectiveness of these mixed-reality activities, this project involved over 1,000 middle and high school students in 50 classes with 9 teachers across six schools in Massachusetts and Virginia, as well as two undergraduate clinical studies. Results demonstrated learning gains for all students, and quasi-experimental studies demonstrated benefits of mixed-reality labs compared to sensor-based physical labs. An overwhelming majority of students found mixed-reality labs helpful for learning and preferred mixed-reality activities to purely virtual approaches.   Broader impacts. Results from our program of research add to the literature on mixed-reality environments as there are very few, if any, studies that use sensor-augmented virtual technologies in authentic classrooms. Findings help refine our knowledge about the relative contribution of physical augmentation in classroom contexts and contribute to a very small set of research that compares mixed-reality or embedded learning technologies to simulations or physical labs. The projectÃ†s exploratory research provides the basis for the development of many more mixed-reality activities. Although the project uses sophisticated software, the simulations are open source and freely available on the project website. Sensors were specifically chosen to take advantage of equipment that many schools already have and use, so even the most cash-strapped schools can have access to these technologies.          Last Modified: 12/18/2015       Submitted by: Jennifer L Chiu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
