<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: Perceptual Learning in Second Language Learners</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>9607.00</AwardTotalIntnAmount>
<AwardAmount>9607</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This dissertation research will test whether second language learners have shared or separate mental representations of speech sounds that occur in both of their languages.  The researchers will recruit English-German and German-English second language learners from the U.S. and Germany.  The participants will listen to English speech in which all instances of one particular sound ("f" or "s") have unusual pronunciations.  Listeners are predicted to adjust their mental representations of the relevant English speech sound categories, as has been demonstrated for monolingual listeners.  Modified sound categories can be revealed through a categorization task in which listeners categorize ambiguous sounds that range on a continuum from "s-" to "f-like".  The listeners will categorize sounds on a continuum in English as well as in German.  The researchers predict that English-German and German-English second language learners will show adjusted sound categories not only in English, but also in German.  This prediction is based on the hypothesis that speech sounds common to two languages, such as "f" or "s" in English and German, have shared or closely interconnected representations in second language learners.&lt;br/&gt;&lt;br/&gt;The participants will be grouped into two proficiency levels in their second language (high/near-native vs. low/intermediate) depending on how they perform in a second language perception test.  Listeners are predicted to differ in their adjustments of the speech sound categories depending on their proficiency level in their second language, and depending on whether English or German is their native language.&lt;br/&gt;&lt;br/&gt;Most language users are not monolingual, but are familiar with more than one language.  This project will contribute to the understanding of the malleability and connectedness of linguistic representations of speech sounds in listeners who know more than one language.  The knowledge gained from this study will advance the scientific understanding of second language learning, speech perception and bilingualism.</AbstractNarration>
<MinAmdLetterDate>08/15/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/22/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1127718</AwardID>
<Investigator>
<FirstName>Marie</FirstName>
<LastName>Huffman</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marie K Huffman</PI_FULL_NAME>
<EmailAddress>Marie.Huffman@stonybrook.edu</EmailAddress>
<PI_PHON>6316321388</PI_PHON>
<NSF_ID>000446096</NSF_ID>
<StartDate>08/15/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Katharina</FirstName>
<LastName>Schuhmann</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katharina Schuhmann</PI_FULL_NAME>
<EmailAddress>Katharina.Schuhmann@gmail.com</EmailAddress>
<PI_PHON>6316329949</PI_PHON>
<NSF_ID>000587122</NSF_ID>
<StartDate>08/15/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName>Stony Brook</CityName>
<StateCode>NY</StateCode>
<ZipCode>117944376</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~9607</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>An issue of long-standing interest is whether phonetically similar sounds in two languages are represented separately in the minds of second language learners, even though this might seem inefficient. One way to address this question is to induce a change in the representation (memory) of a specific sound contrast for one language, and to test whether a similar sound contrast in the other language is also affected. If the representations of phonetically similar sounds in two languages were fully independent, we would expect that perceptual learning in one language would not extend to the other language.</p> <p class="p1">We carried out several "perceptual learning" studies to probe the relationship between listeners&rsquo; representations for /f/ and /s/ as well as /v/ and /z/ in English and German. First, all listeners were exposed to English words with an atypical /f/ or /s/ sound. Second, listeners had to categorize various levels of mixed sounds (mixed between /f/ and /s/ or between /v/ and /z/) in English and German.&nbsp;</p> <p class="p1">Our four perceptual learning studies with English learners of German and German learners of English indicate that listeners have separate yet interconnected representations (memories) for speech sounds in their minds. After exposure to unusual sounds in English, beginning-level learners of German only show adaptation effects in English as well as in German if the second language (German) is activated and used on a regular basis. A language that is not utlized enough will not be part of the grammatical network of activated linguistic units while subtle retuning effects take place, and will therefore not show re-actions to the atypical speech input.</p> <p class="p1">In addition, the level of proficiency in the second language (here: German) influences how strong the adaptation effects are in German. The perception of German sounds (e.g. /f/ vs. /s/) in beginning English learners of German shifts more than the perception of sounds in their native language English (e.g. also /f/ vs. /s/). This large effect in the non-native language results from less experience with the second language, less input, and thus fewer memories for the second language and its sounds and words. As a consequence, the memories for sounds in a non-native language are weaker, less stabilized, and therefore more susceptible to forces of adaptation.</p> <p class="p1">Finally, our study with German learners of English in Germany shows that intermediate-to-advanced nonnative listeners can also adjust phoneme categories in their nonnative language when they are exposed to unusual sounds in their L2. At the same time, perceptual adaptations in an L2 seem to be specific to particular sound contrasts (here: /f/ vs. /s/) and do not generalize to other contrasts (here: /v/ vs. /z/). This outcome highlights the similarities and differences in how native and nonnative listeners process atypical speech input.</p> <p class="p1">Overall, we conclude that these studies provide evidence that speech sounds common to listeners&rsquo; L1 and L2 have separate yet interconnected mental representations (memories) for speech perception.</p> <p class="p1">&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/21/2015<br>      Modified by: Katharina&nbsp;Schuhmann</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ An issue of long-standing interest is whether phonetically similar sounds in two languages are represented separately in the minds of second language learners, even though this might seem inefficient. One way to address this question is to induce a change in the representation (memory) of a specific sound contrast for one language, and to test whether a similar sound contrast in the other language is also affected. If the representations of phonetically similar sounds in two languages were fully independent, we would expect that perceptual learning in one language would not extend to the other language. We carried out several "perceptual learning" studies to probe the relationship between listenersÆ representations for /f/ and /s/ as well as /v/ and /z/ in English and German. First, all listeners were exposed to English words with an atypical /f/ or /s/ sound. Second, listeners had to categorize various levels of mixed sounds (mixed between /f/ and /s/ or between /v/ and /z/) in English and German.  Our four perceptual learning studies with English learners of German and German learners of English indicate that listeners have separate yet interconnected representations (memories) for speech sounds in their minds. After exposure to unusual sounds in English, beginning-level learners of German only show adaptation effects in English as well as in German if the second language (German) is activated and used on a regular basis. A language that is not utlized enough will not be part of the grammatical network of activated linguistic units while subtle retuning effects take place, and will therefore not show re-actions to the atypical speech input. In addition, the level of proficiency in the second language (here: German) influences how strong the adaptation effects are in German. The perception of German sounds (e.g. /f/ vs. /s/) in beginning English learners of German shifts more than the perception of sounds in their native language English (e.g. also /f/ vs. /s/). This large effect in the non-native language results from less experience with the second language, less input, and thus fewer memories for the second language and its sounds and words. As a consequence, the memories for sounds in a non-native language are weaker, less stabilized, and therefore more susceptible to forces of adaptation. Finally, our study with German learners of English in Germany shows that intermediate-to-advanced nonnative listeners can also adjust phoneme categories in their nonnative language when they are exposed to unusual sounds in their L2. At the same time, perceptual adaptations in an L2 seem to be specific to particular sound contrasts (here: /f/ vs. /s/) and do not generalize to other contrasts (here: /v/ vs. /z/). This outcome highlights the similarities and differences in how native and nonnative listeners process atypical speech input. Overall, we conclude that these studies provide evidence that speech sounds common to listenersÆ L1 and L2 have separate yet interconnected mental representations (memories) for speech perception.                  Last Modified: 09/21/2015       Submitted by: Katharina Schuhmann]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
