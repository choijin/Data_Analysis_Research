<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: SMALL: Modeling Voice Source Transformation in Monolingual and Crosslingual Non-parallel Voice Conversion Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>244637.00</AwardTotalIntnAmount>
<AwardAmount>252637</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Voice conversion (VC) systems transform segments of speech from a given source speaker so that it&lt;br/&gt;can be identified as spoken by a specified target speaker. Currently, standard VC systems require&lt;br/&gt;parallel training on extensively labeled sets of speech data where the source and target speaker share&lt;br/&gt;equivalent content for building direct mapping models. This project builds on the concepts of nonparallel&lt;br/&gt;VC systems reducing the need for labeled and shared speech content between source and target&lt;br/&gt;speakers as well as allowing for both intra-lingual and cross-lingual conversion scenarios. This project&lt;br/&gt;focuses on two main areas: (1) Building a framework for non-parallel VC without explicit phonetic,&lt;br/&gt;sound, word, or sentence level labels, and (2) Providing effective target speaker mapping to obtain&lt;br/&gt;converted speech with as good as or better quality compared to current VC systems. The VC&lt;br/&gt;framework consists of three main components: (1) A speaker independent language model; (2) An&lt;br/&gt;algorithm for model adaptation to target speaker; (3) A speech synthesis block to generate converted&lt;br/&gt;speech from a target-adapted language model.&lt;br/&gt;&lt;br/&gt;This project will provide a broad framework for applications such as personalization of assistive textto-&lt;br/&gt;speech (TTS) systems, foreign language learning, and as a possible component in speech-to-speech&lt;br/&gt;translation systems. This project will support graduate student research and provide results for&lt;br/&gt;community distribution through conference and journal submission. Additionally, an open-source&lt;br/&gt;software toolset will be developed and freely distributed. The project will also be used in outreach for&lt;br/&gt;underrepresented groups in Science Technology Engineering and Mathematics (STEM) disciplines.</AbstractNarration>
<MinAmdLetterDate>07/20/2011</MinAmdLetterDate>
<MaxAmdLetterDate>05/07/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116475</AwardID>
<Investigator>
<FirstName>Elliot</FirstName>
<LastName>Moore</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elliot Moore</PI_FULL_NAME>
<EmailAddress>em80@mail.gatech.edu</EmailAddress>
<PI_PHON>4043857354</PI_PHON>
<NSF_ID>000062117</NSF_ID>
<StartDate>07/20/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~80327</FUND_OBLG>
<FUND_OBLG>2012~172310</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Voice conversion (VC) systems aim to transform segments of speech from a given source speaker so that it can be identified as spoken by a specified target speaker.&nbsp; Despite progress in VC systems, the practicality of their use has been limited due to significant constraints imposed by existing systems (e.g., one-to-one mapping, parallel training data, labeled/aligned data, etc.).&nbsp; VC systems could have many uses in areas such as: personalization of text-to-speech systems, movie dubbing, foreign language learning, and as a component in speech-to-speech translation systems if a more generous framework was realized.&nbsp;</p> <p>A first step towards creating an effective VC system is to determine how different speech features affect a human&rsquo;s natural ability to identify particular speakers. Regardless of which features are used to perform the conversion, a VC system needs a training stage to define the mapping parameters between the features of source speakers to the features of the target speaker. The training usually involves finding segments of speech from a single source and a single target that contain the same sounds for alignment and then building a mapping function from the resulting pairs of matching features. This method of training is referred to as <em>parallel training</em> (i.e., a one-to-one correspondence). Most of the previous work on voice conversion has focused on the parallel training case.&nbsp; Later work has begun to deal with the more general problem of non-parallel voice conversion, where the source and target speakers need not share the same training data.&nbsp; This method of training has the potential advantage of providing a better framework for developing practical applications of VC technologies without the constraints of a single source/target mapping and it is a very open and active area for research.&nbsp; The research in this proposal focused on two main areas: (1) Building a framework for non-parallel voice conversion and (2) Providing effective target speaker mapping to obtain converted speech with as good as or better quality compared to current VC systems while not compromising effective identity conversion.&nbsp;</p> <p>While the performance of VC systems has been improving steadily since the first models were proposed, there are many unsolved challenges that limit the wide spread use of the current systems.&nbsp; One challenge is the current trade-off between the effectiveness of the identity conversion and the quality of the converted speech. Generally, improving identity conversion in VC systems has led to a reduction in perceived quality (according to subjective listening tests).&nbsp; Another challenge is the need for extensively labeled speech data for mapping purposes which can limit the general application of VC systems.&nbsp; This proposal investigated a new methodology for performing non-parallel voice conversion to improve performance in identity conversion as well as speech quality over existing VC systems (parallel or non-parallel based).&nbsp; The developed methodology was designed to expand the usability of VC systems with a framework robust to intra- and cross-lingual voice conversion applications.&nbsp;</p> <p class="PreformattedText">The system developed in this project was compared with two other state-of-the-art VC systems using listening tests for both speech quality and identity conversion. The developed method achieved:</p> <p class="PreformattedText">- statistically equivalent or superior speech quality on the converted speech than the two alternative systems.</p> <p class="PreformattedText">- superior identity conversion scores than the two alternative systems.</p> <p class="PreformattedText">- superior consistency for both conversion quality and speaker identity in cross- and same- gender voice conversions. &nbsp;</p> <p class="PreformattedText">In summary, the work completed for this pr...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Voice conversion (VC) systems aim to transform segments of speech from a given source speaker so that it can be identified as spoken by a specified target speaker.  Despite progress in VC systems, the practicality of their use has been limited due to significant constraints imposed by existing systems (e.g., one-to-one mapping, parallel training data, labeled/aligned data, etc.).  VC systems could have many uses in areas such as: personalization of text-to-speech systems, movie dubbing, foreign language learning, and as a component in speech-to-speech translation systems if a more generous framework was realized.   A first step towards creating an effective VC system is to determine how different speech features affect a humanÃ†s natural ability to identify particular speakers. Regardless of which features are used to perform the conversion, a VC system needs a training stage to define the mapping parameters between the features of source speakers to the features of the target speaker. The training usually involves finding segments of speech from a single source and a single target that contain the same sounds for alignment and then building a mapping function from the resulting pairs of matching features. This method of training is referred to as parallel training (i.e., a one-to-one correspondence). Most of the previous work on voice conversion has focused on the parallel training case.  Later work has begun to deal with the more general problem of non-parallel voice conversion, where the source and target speakers need not share the same training data.  This method of training has the potential advantage of providing a better framework for developing practical applications of VC technologies without the constraints of a single source/target mapping and it is a very open and active area for research.  The research in this proposal focused on two main areas: (1) Building a framework for non-parallel voice conversion and (2) Providing effective target speaker mapping to obtain converted speech with as good as or better quality compared to current VC systems while not compromising effective identity conversion.   While the performance of VC systems has been improving steadily since the first models were proposed, there are many unsolved challenges that limit the wide spread use of the current systems.  One challenge is the current trade-off between the effectiveness of the identity conversion and the quality of the converted speech. Generally, improving identity conversion in VC systems has led to a reduction in perceived quality (according to subjective listening tests).  Another challenge is the need for extensively labeled speech data for mapping purposes which can limit the general application of VC systems.  This proposal investigated a new methodology for performing non-parallel voice conversion to improve performance in identity conversion as well as speech quality over existing VC systems (parallel or non-parallel based).  The developed methodology was designed to expand the usability of VC systems with a framework robust to intra- and cross-lingual voice conversion applications.  The system developed in this project was compared with two other state-of-the-art VC systems using listening tests for both speech quality and identity conversion. The developed method achieved: - statistically equivalent or superior speech quality on the converted speech than the two alternative systems. - superior identity conversion scores than the two alternative systems. - superior consistency for both conversion quality and speaker identity in cross- and same- gender voice conversions.   In summary, the work completed for this project resulted in a flexible, many(source)-to-one(target) VC system able to perform both monolingual and cross-lingual conversion using parallel or non-parallel training without sacrificing (and in many cases improving) identity and converted speech quality versus other current state-of-the-art VC systems.       ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
