<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: Exploring augmented reality to improve learning by deaf children in planetariums</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Christopher Hoadley</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project is investigating the use of head-mounted augmented reality (AR) to improve learning outcomes among deaf and hard of hearing learners in situations that make learning logistically-challenging for them, specifically presentation situations where there is also some scenario that needs to be focused on visually. The work is being carried out in planetaria, where learners wear a monocle that displays a signer in a way that allows the learner to look at both the signed interpretation of the presentation and the scenario of interest at the same time. The design of the technology and way it is being used is informed by the literature on cognitive load and by literature on multimedia learning theory (Mayer, 2005). Results are applicable to a wide variety of logistically-challenging situations for deaf/hoh learners, including the kinds of informal learning venues that often excite the passions of hearing learners and perhaps in classrooms as well.&lt;br/&gt;&lt;br/&gt;Presentations, even when a signer is available, are often logistically-difficult for the deaf and hard-of-hearing population to take advantage of well. Moving attention back and forth between the interpreter to the objects or scenarios being described makes it difficult to follow a presentation and get everything out of it that a hearing person can get. This project is aiming to ameliorate this problem by designing technology that will project the interpreter's signs in the same field of vision as the object or scenario being discussed and learning how to use that technology well.</AbstractNarration>
<MinAmdLetterDate>08/27/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/27/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1124548</AwardID>
<Investigator>
<FirstName>Fred</FirstName>
<LastName>Mangrubang</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fred R Mangrubang</PI_FULL_NAME>
<EmailAddress>fred.mangrubang@gallaudet.edu</EmailAddress>
<PI_PHON>2026515300</PI_PHON>
<NSF_ID>000474058</NSF_ID>
<StartDate>08/27/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Hintz</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric G Hintz</PI_FULL_NAME>
<EmailAddress>hintz@physics.byu.edu</EmailAddress>
<PI_PHON>8014224168</PI_PHON>
<NSF_ID>000275215</NSF_ID>
<StartDate>08/27/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Jones</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Jones</PI_FULL_NAME>
<EmailAddress>jones@cs.byu.edu</EmailAddress>
<PI_PHON>8014222217</PI_PHON>
<NSF_ID>000353002</NSF_ID>
<StartDate>08/27/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ron</FirstName>
<LastName>Proctor</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ron Proctor</PI_FULL_NAME>
<EmailAddress>ronproctor@science.weber.edu</EmailAddress>
<PI_PHON>8016266055</PI_PHON>
<NSF_ID>000536236</NSF_ID>
<StartDate>08/27/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brigham Young University</Name>
<CityName>Provo</CityName>
<ZipCode>846021231</ZipCode>
<PhoneNumber>8014223360</PhoneNumber>
<StreetAddress>A-285 ASB</StreetAddress>
<StreetAddress2><![CDATA[Campus Drive]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009094012</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BRIGHAM YOUNG UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001940170</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brigham Young University]]></Name>
<CityName>Provo</CityName>
<StateCode>UT</StateCode>
<ZipCode>846021231</ZipCode>
<StreetAddress><![CDATA[3328 TMCB]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1545</Code>
<Text>RES IN DISABILITIES ED</Text>
</ProgramElement>
<ProgramElement>
<Code>7259</Code>
<Text>AISL</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>1545</Code>
<Text>RES IN DISABILITIES ED</Text>
</ProgramReference>
<ProgramReference>
<Code>7259</Code>
<Text>INFORMAL SCIENCE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The purpose of this project was to understand how head mounted displays (HMDs) could be configured and used to improve science education for deaf or hard of hearing children by improving access to sign language. &nbsp;An HMD, like Google Glass, is a head-worn device that places a video display screen in front of the user's eyes. &nbsp; Viewing sign language in HMDs may improve access to sign language by allowing the viewer to see the signer wherever the viewer looks. &nbsp;We studied viewing sign language in HMDs in planetarium shows narrated in American Sign Language (ASL). &nbsp;It is difficult to view a planetarium show in ASL because the viewer must constantly switch their view between the signer and the show projected on the dome ceiling. &nbsp;</span></p> <p><span>Our project had two phases: interviewing teachers of deaf children and evaluating HMD systems.&nbsp;&nbsp; We visited 14 schools primarily in the south eastern United States to meet with teachers and to observe classroom instruction. &nbsp;The purpose of these visits was to understand how teachers use ASL to teach science concepts.&nbsp; That understanding would inform our use of HMDs and future projects.&nbsp; &nbsp;During those visits we found that the most significant challenge in science education in ASL is the diverse language background of students, students&rsquo; reading levels and the lack of science vocabulary.</span></p> <p><span>We built 4 systems for viewing ASL in HMDs and evaluated them in 8 different sessions with a total of 121 children who are deaf or hard of hearing.&nbsp; &nbsp;The evaluations varied but all included ASL narration of a planetarium show.&nbsp; From these evaluations we learned that viewing ASL in an HMD in planetarium show can have a positive impact on learning but the display and video transmission system must be properly adjusted to place the signer in the center of the field of view and to avoid delays or jumps in the video stream.&nbsp; </span></p> <p><span>The broader impact of the project is that it will improve accessibility to science education for children who are deaf or hard of hearing.&nbsp; This will create new opportunities for participation in science and technology.&nbsp;&nbsp; The project also resulted in training opportunities for 21 university students, 7 of whom were deaf or hard of hearing, who participated as research assistants.&nbsp;</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/30/2015<br>      Modified by: Michael&nbsp;Jones</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The purpose of this project was to understand how head mounted displays (HMDs) could be configured and used to improve science education for deaf or hard of hearing children by improving access to sign language.  An HMD, like Google Glass, is a head-worn device that places a video display screen in front of the user's eyes.   Viewing sign language in HMDs may improve access to sign language by allowing the viewer to see the signer wherever the viewer looks.  We studied viewing sign language in HMDs in planetarium shows narrated in American Sign Language (ASL).  It is difficult to view a planetarium show in ASL because the viewer must constantly switch their view between the signer and the show projected on the dome ceiling.    Our project had two phases: interviewing teachers of deaf children and evaluating HMD systems.   We visited 14 schools primarily in the south eastern United States to meet with teachers and to observe classroom instruction.  The purpose of these visits was to understand how teachers use ASL to teach science concepts.  That understanding would inform our use of HMDs and future projects.   During those visits we found that the most significant challenge in science education in ASL is the diverse language background of students, studentsÃ† reading levels and the lack of science vocabulary.  We built 4 systems for viewing ASL in HMDs and evaluated them in 8 different sessions with a total of 121 children who are deaf or hard of hearing.   The evaluations varied but all included ASL narration of a planetarium show.  From these evaluations we learned that viewing ASL in an HMD in planetarium show can have a positive impact on learning but the display and video transmission system must be properly adjusted to place the signer in the center of the field of view and to avoid delays or jumps in the video stream.    The broader impact of the project is that it will improve accessibility to science education for children who are deaf or hard of hearing.  This will create new opportunities for participation in science and technology.   The project also resulted in training opportunities for 21 university students, 7 of whom were deaf or hard of hearing, who participated as research assistants.           Last Modified: 11/30/2015       Submitted by: Michael Jones]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
