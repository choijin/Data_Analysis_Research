<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RAPID: Preventing the Spread of Coronavirus with Efficient Deep Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2020</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>125000.00</AwardTotalIntnAmount>
<AwardAmount>125000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The novel coronavirus, COVID-19 is a pandemic infecting people in the United States and around the world. It is of utmost importance to prevent the fast spread of the virus. This project will use artificial intelligence (AI) methods to slow down the infection by encouraging proper wear of Personal Protective Equipment (PPE) by hospital staff and by supporting social distancing. The planned method will help monitor dangerous activities pointed out by Center for Disease Control (CDC), such as hand-to-face contact, touching inside or crossing arms when taking off the gown and masks and social distancing. It will advance the national health, protect the healthcare workers and help the whole nation combat the pandemic. &lt;br/&gt;&lt;br/&gt;Video understanding and activity recognition have made great progress in recent years. This project will apply artificial intelligence on a mobile platform for efficient activity recognition techniques to guide people's activities in healthcare settings, including patients', health care workers' and community residents'. To protect privacy in transmission to the cloud, the project applies the team's work on model compression techniques and neural architecture search to make the AI more compact and efficient so that it can be deployed on edge devices. As a result, videos can be locally processed; only key information or the detection result is sent over the cloud, preserving people's privacy. Finally, the project will efficiently deploy such algorithms on mobile devices and make it freely available in the hospitals.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/09/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/09/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2027266</AwardID>
<Investigator>
<FirstName>Song</FirstName>
<LastName>Han</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Song Han</PI_FULL_NAME>
<EmailAddress>songhan@MIT.EDU</EmailAddress>
<PI_PHON>6508622761</PI_PHON>
<NSF_ID>000762347</NSF_ID>
<StartDate>06/09/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>158Y</Code>
<Text>COVID-19 Research</Text>
</ProgramElement>
<ProgramReference>
<Code>096Z</Code>
<Text>COVID-19 Research</Text>
</ProgramReference>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<Appropriation>
<Code>1N20</Code>
<Name>R&amp;RA CARES Act DEFC N</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~125000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>To slow down the infection of Coronavirus, we need encourage social distancing, limit people's contact and activities, and properly wear face masks. Video understanding have made great progress in recent years to recognize people&rsquo;s activities. We applied mobile AI technologies to efficiently recognize people's activities on edge devices. AI can help monitor dangerous activities pointed out by CDC, such as massive gathering and not properly wearing face masks.&nbsp; Privacy would be a big concern if the raw video is transmitted to the cloud. Therefore, we applied our model compression technique and neural architecture search to make AI more compact and efficient, so that we are able to deploy AI on tiny, cheap mobile devices without transmitting the data to the cloud, preserving people's privacy, while the accuracy is not compromised.</p> <p>&nbsp;</p> <p>We published a paper &ldquo;<a href="https://arxiv.org/pdf/2007.10319.pdf">MCUNet: Tiny Deep Learning on IoT Devices</a>&rdquo; which is accepted by NeurIPS&rsquo;20 as a spotlight presentation. Only 3% of the submitted papers receives spotlights. Enabling powerful AI on tiny microcontrollers (MCU) is challenging, since MCU has 2-3 orders of magnitude less memory than desktop CPUs. The existing neural architecture design space does not fit MCUs. We found that the memory bottleneck is the intermediate activations, not weights. Prior model compression techniques can not solve this issue. Our <a href="https://arxiv.org/pdf/2007.10319.pdf">MCUNet</a> first re-designs the design space targeting activation reduction, then builds the once-for-all network on the optimized design space. We jointly design the efficient neural architecture (TinyNAS) and the lightweight inference engine (TinyEngine) that introduces memory-efficient scheduling and in-place depth wise convolution. MCUNet enables ImageNet classification on microcontrollers that have only 1MB of flash. Applied to person detection MCUNet can achieve &gt;90% accuracy under 32kB SRAM low-end MCUs costing less than $5. It outperforms Google's TF-Lite Micro and ARM's CMSIS-NN by a large margin.</p> <p>&nbsp;</p> <p>We have successfully built a <a href="https://www.youtube.com/watch?v=AFsExPbxIiA">face mask detection demo</a> on tiny a tiny device: STM32 microcontrollers. It&rsquo;s common to build such demo on CPU/GPU and AI chips, but MCUNet is a pioneering work to deploy it on tiny microcontrollers that costs less than $5. We can use it detect if people is wearing mask; we can also count the number of people in the view and prevent mass gathering. The cost is so cheap that every restaurant would be able to afford it. We compressed the model to only 252KB, taking 18.4M MACs, which make it possible to fit tiny microcontrollers that is cheap and low power. No data needs to be sent to the cloud, which preserves people&rsquo;s privacy. With MCUNet, we are not only able to detect person, faces and masks on the mobile phone, but also even cheaper microcontrollers that has 2 orders of magnitude less memory, which is beyond the expectation of our initial proposal. Our study suggests that the era of tiny machine learning on IoT devices has arrived.</p> <p>&nbsp;</p> <p>MCUNet was broadly covered by the media in multiple languages, including:</p> <p><span>&ndash; </span><span><strong>Wired</strong>,&nbsp;<a href="https://www.wired.com/story/ai-algorithms-slimming-fit-fridge/"><span>AI&nbsp;Algorithms&nbsp;Are&nbsp;Slimming&nbsp;Down&nbsp;to&nbsp;Fit&nbsp;in&nbsp;Your&nbsp;Fridge</span></a>&nbsp;</span></p> <p><span>&ndash;<strong> MIT News</strong>,&nbsp;<a href="https://news.mit.edu/2020/iot-deep-learning-1113"><span>System brings deep learning to &ldquo;internet of things&rdquo; devices</span></a></span></p> <p><span>&ndash;&nbsp;<strong>Stacey on IoT</strong>,&nbsp;<a href="https://staceyoniot.com/researchers-take-a-3-pronged-approach-to-edge-ai/"><span>Researchers&nbsp;take&nbsp;a&nbsp;3-pronged&nbsp;approach&nbsp;to&nbsp;Edge&nbsp;AI&nbsp;</span></a></span></p> <p><span><strong>&ndash; Morning Brew</strong>, <a href="https://www.morningbrew.com/emerging-tech/stories/2020/12/07/researchers-figured-fit-ai-ever-onto-internet-things-microchips"><span>Researchers Figured Out How to Fit More AI Than Ever onto Internet of Things Microchips</span></a></span></p> <p><span><strong>&ndash; IBM</strong>,&nbsp;<a href="https://mitibmwatsonailab.mit.edu/research/blog/mcunet-tiny-deep-learning-on-iot-devices/"><span>New IBM-MIT system brings AI to microcontrollers &ndash; paving the way to &lsquo;smarter&rsquo; IoT</span></a></span></p> <p><span><strong>&ndash; Analytics Insight</strong>, <a href="https://www.analyticsinsight.net/amalgamating-ml-and-iot-in-smart-home-devices/"><span>Amalgamating Ml And Iot In Smart Home Devices</span></a></span></p> <p><span><strong>&ndash; Techable</strong>,&nbsp;<a href="https://techable.jp/archives/142462"><span>MIT</span><span>&#12364;</span><span>IoT</span><span>&#12487;&#12496;&#12452;&#12473;&#21521;&#12369;&#12398;&#12467;&#12531;&#12497;&#12463;&#12488;&#12394;</span><span>AI</span><span>&#12471;&#12473;&#12486;&#12512;&#12434;&#38283;&#30330;&#65281;</span></a></span></p> <p><span><strong>&ndash; Tendencias,</strong>&nbsp;<span><a href="https://tendencias21.levante-emv.com/el-aprendizaje-profundo-impulsa-el-internet-de-las-cosas.html">El aprendizaje profundo impulsa el Internet de las cosas</a></span></span></p> <div><span><br /></span></div> <p>&nbsp;</p><br> <p>            Last Modified: 07/02/2021<br>      Modified by: Song&nbsp;Han</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/2027266/2027266_10675788_1625260129230_ScreenShot2021-07-02at5.07.32PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2027266/2027266_10675788_1625260129230_ScreenShot2021-07-02at5.07.32PM--rgov-800width.jpg" title="MCUNet"><img src="/por/images/Reports/POR/2021/2027266/2027266_10675788_1625260129230_ScreenShot2021-07-02at5.07.32PM--rgov-66x44.jpg" alt="MCUNet"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Face mask detection on MCU</div> <div class="imageCredit">MIT HAN Lab</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Song&nbsp;Han</div> <div class="imageTitle">MCUNet</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ To slow down the infection of Coronavirus, we need encourage social distancing, limit people's contact and activities, and properly wear face masks. Video understanding have made great progress in recent years to recognize people’s activities. We applied mobile AI technologies to efficiently recognize people's activities on edge devices. AI can help monitor dangerous activities pointed out by CDC, such as massive gathering and not properly wearing face masks.  Privacy would be a big concern if the raw video is transmitted to the cloud. Therefore, we applied our model compression technique and neural architecture search to make AI more compact and efficient, so that we are able to deploy AI on tiny, cheap mobile devices without transmitting the data to the cloud, preserving people's privacy, while the accuracy is not compromised.     We published a paper "MCUNet: Tiny Deep Learning on IoT Devices" which is accepted by NeurIPS’20 as a spotlight presentation. Only 3% of the submitted papers receives spotlights. Enabling powerful AI on tiny microcontrollers (MCU) is challenging, since MCU has 2-3 orders of magnitude less memory than desktop CPUs. The existing neural architecture design space does not fit MCUs. We found that the memory bottleneck is the intermediate activations, not weights. Prior model compression techniques can not solve this issue. Our MCUNet first re-designs the design space targeting activation reduction, then builds the once-for-all network on the optimized design space. We jointly design the efficient neural architecture (TinyNAS) and the lightweight inference engine (TinyEngine) that introduces memory-efficient scheduling and in-place depth wise convolution. MCUNet enables ImageNet classification on microcontrollers that have only 1MB of flash. Applied to person detection MCUNet can achieve &gt;90% accuracy under 32kB SRAM low-end MCUs costing less than $5. It outperforms Google's TF-Lite Micro and ARM's CMSIS-NN by a large margin.     We have successfully built a face mask detection demo on tiny a tiny device: STM32 microcontrollers. It’s common to build such demo on CPU/GPU and AI chips, but MCUNet is a pioneering work to deploy it on tiny microcontrollers that costs less than $5. We can use it detect if people is wearing mask; we can also count the number of people in the view and prevent mass gathering. The cost is so cheap that every restaurant would be able to afford it. We compressed the model to only 252KB, taking 18.4M MACs, which make it possible to fit tiny microcontrollers that is cheap and low power. No data needs to be sent to the cloud, which preserves people’s privacy. With MCUNet, we are not only able to detect person, faces and masks on the mobile phone, but also even cheaper microcontrollers that has 2 orders of magnitude less memory, which is beyond the expectation of our initial proposal. Our study suggests that the era of tiny machine learning on IoT devices has arrived.     MCUNet was broadly covered by the media in multiple languages, including:  &ndash; Wired, AI Algorithms Are Slimming Down to Fit in Your Fridge   &ndash; MIT News, System brings deep learning to "internet of things" devices  &ndash; Stacey on IoT, Researchers take a 3-pronged approach to Edge AI   &ndash; Morning Brew, Researchers Figured Out How to Fit More AI Than Ever onto Internet of Things Microchips  &ndash; IBM, New IBM-MIT system brings AI to microcontrollers &ndash; paving the way to ‘smarter’ IoT  &ndash; Analytics Insight, Amalgamating Ml And Iot In Smart Home Devices  &ndash; Techable, MIT&#12364;IoT&#12487;&#12496;&#12452;&#12473;&#21521;&#12369;&#12398;&#12467;&#12531;&#12497;&#12463;&#12488;&#12394;AI&#12471;&#12473;&#12486;&#12512;&#12434;&#38283;&#30330;&#65281;  &ndash; Tendencias, El aprendizaje profundo impulsa el Internet de las cosas            Last Modified: 07/02/2021       Submitted by: Song Han]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
