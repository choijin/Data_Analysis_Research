<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>FAI: causal and semi-parametric inference for explanations of disparities and disparity-correcting modeling</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>399923.00</AwardTotalIntnAmount>
<AwardAmount>399923</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
<PO_EMAI>tleen@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As learning algorithms become ubiquitous in our lives, many have expressed concerns about the potentially harmful biases and disparities that may arise when these algorithms use sensitive features in the data --- such as race, age, gender, or health --- inappropriately.  This project aims to understand and correct for these disparities using causal inference, which aims to use data to quantify cause--effect relationships. Such relationships can be uncovered by trying to predict the change in an effect when a cause variable takes on a different value than one it usually attains. For example, ethnic disparities in health outcomes may arise from different rates of pre-existing comorbidities in different ethnic groups, or from differences in care arising from implicit biases, or from some other mechanisms unmeasured in the data. The indirect effect on health outcome of group-dependent rates of comorbidities can be conceptualized as follows. Measure the health outcomes in patients from ethnic Group A, then use a reliable model to predict outcomes for the same patients with comorbidity rates artificially set to that of ethnic Group B, while leaving everything else the same, and compare the two.  Disparity between the measured and predicted health outcomes point to differing comorbidity rates as the cause. Similarly, a direct effect could be revealed by comparing health outcomes in patients from ethnic Group A with predicted health outcomes in that same group with all variables participating in known indirect mechanisms giving rise to disparities left intact, but the variable indicating ethnicity changed to that for Group B.  Such a direct effect may be viewed as the proportion of the overall effect of ethnicity on the outcome not explained by indirect effects. This project aims to develop methods that use data to predict how such hypothetical comparisons would turn out, use the results to better understand mechanisms of disparities in healthcare, and build predictive models that are aware, and can correct for undesirable mechanisms of disparity.&lt;br/&gt;&lt;br/&gt;In this project, the investigator aims to address conceptual, methodological, and practical gaps in explaining disparities via their causal mechanisms and building models and tools that can correct for mechanisms deemed impermissible. An example of such a mechanism is a direct dependence of a decision or outcome on perceived race or gender.  The investigator will develop methods that can assess the extent to which disparities in outcomes with respect to a sensitive feature can be attributed to distinct causal pathways. To address challenges causal inference faces in complex high-dimensional settings, the investigator will adopt modern semi-parametric methods that are able to use machine learning models while retaining desirable properties of robustness and rapids rates of convergence. In addition, the investigator will develop a novel combination of methods from causal and semi-parametric inference, and constrained optimization to create predictive models and decision support tools that use data efficiently while preventing impermissible mechanisms of disparity from operating, for instance by ensuring that perceived ethnicity has no direct effect on outcomes or decisions made.  The approach will be applied to quantifying disparities and building decision support tools using a complex data set obtained from electronic health records at Johns Hopkins University.  All methods will be implemented in an open-source software package Ananke.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/20/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040804</AwardID>
<Investigator>
<FirstName>Ilya</FirstName>
<LastName>Shpitser</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ilya Shpitser</PI_FULL_NAME>
<EmailAddress>ilyas@cs.jhu.edu</EmailAddress>
<PI_PHON>9166671382</PI_PHON>
<NSF_ID>000727572</NSF_ID>
<StartDate>08/20/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Sussman</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marc S Sussman</PI_FULL_NAME>
<EmailAddress>msussma1@jhmi.edu</EmailAddress>
<PI_PHON>4109553285</PI_PHON>
<NSF_ID>000804874</NSF_ID>
<StartDate>08/20/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Glenn</FirstName>
<LastName>Whitman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Glenn Whitman</PI_FULL_NAME>
<EmailAddress>gwhitman@jhmi.edu</EmailAddress>
<PI_PHON>4109553285</PI_PHON>
<NSF_ID>000804922</NSF_ID>
<StartDate>08/20/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182686</ZipCode>
<StreetAddress><![CDATA[1101 E 33rd St,Suite B001]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>114Y</Code>
<Text>Fairness in Artificial Intelli</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~399923</FUND_OBLG>
</Award>
</rootTag>
