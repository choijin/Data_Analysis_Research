<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Building a Novel, Interactive Artificial Intelligence Software Platform to Improve Communication in Autism</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>04/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>255367.00</AwardTotalIntnAmount>
<AwardAmount>255367</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Diane Hickey</SignBlockName>
<PO_EMAI>dhickey@nsf.gov</PO_EMAI>
<PO_PHON>7032928875</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact /commercial potential of this Small Business Innovation Research (SBIR) Phase I project will be the creation of a tool for caregivers and educators of children with speech impairments, particularly those with autism spectrum disorder. Left untreated, these impairments have lasting impacts on quality of life but remain difficult and expensive to treat; the market for autism treatment is estimated at $3.2 B worldwide. This project will expand the capabilities to provide treatment in non-clinical settings. The technology to be developed will include automated evaluation of speech development levels in the absence of a speech pathologist. In addition, technology will be pioneered that allows activities and lessons to be individually customized and continuously updated for each learner. These two advances will form the technological core of a new product designed specifically to meet the needs of caretakers, teachers and families of children with autism. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project involves research and development of advanced technologies for the treatment of speech impairment associated with autism spectrum disorder. Artificial intelligence will be applied to two fundamental challenges, the automated determination of speech development levels in the absence of a speech pathologist; and the assignment of activities and lessons in response to user input. This project will collect labeled text from language learners at various stages of development to form a training corpus. Machine learning will then be used to build algorithms for scoring engines to make learning assessments independent of a clinician. In parallel, the development and application of a business rules management system will allow the platform to accept user input such as an image, word, or phrase; and it will output new words and phrases for the learner to attempt. The system will follow a decision logic that considers the both the user input and the previously assigned language development level. The goal of this research is to produce algorithms that closely match the labeled assessments of language development and decision logic that assigns activities appropriate for each level.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/01/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/13/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2025836</AwardID>
<Investigator>
<FirstName>Lois</FirstName>
<LastName>Brady</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lois J Brady</PI_FULL_NAME>
<EmailAddress>loisjeanbrady@gmail.com</EmailAddress>
<PI_PHON>9258120037</PI_PHON>
<NSF_ID>000668110</NSF_ID>
<StartDate>09/01/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>iTherapy LLC</Name>
<CityName>Martinez</CityName>
<ZipCode>945531313</ZipCode>
<PhoneNumber>9258120037</PhoneNumber>
<StreetAddress>649 Main Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078838337</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ITHERAPY, LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[iTherapy LLC]]></Name>
<CityName>Martinez</CityName>
<StateCode>CA</StateCode>
<ZipCode>945531313</ZipCode>
<StreetAddress><![CDATA[649 Main Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>1707</Code>
<Text>ADVANCED LEARNING TECHNOLOGIES</Text>
</ProgramReference>
<ProgramReference>
<Code>8031</Code>
<Text>Education Products</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~255367</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-9a2a7b93-7fff-982c-8b0e-8035bb0bc4b8"> <p dir="ltr"><span>Autism Spectrum Disorder (ASD) is a neurodevelopmental communication disorder affecting over 3.5 million Americans that results in functional language delays and behavioral challenges. These delays often result in limited speech and increased communication difficulties -- approximately 40% of people in the ASD population are minimally verbal or non-verbal, having increased communication challenges. While many technologies and teaching tools have surfaced to assess the needs of non-verbal children with ASD, these often rely on the physical presence of a Speech Language Pathologist, teacher, or parent. This creates a sizable bottleneck for those with ASD to further learn and practice language skills.&nbsp;</span></p> <br /> <p dir="ltr"><span>It was the goal of this SBIR Phase I to explore the feasibility of an AI Language Coach for non-verbal or minimally verbal children with ASD. The main objectives of this 12-month project were to establish the protocols for data collection and processing, train an analysis tool to assess user proficiency, and construct a pilot recommendation engine. The original end goal for this project was to create an AI algorithm that recommended alternate phrases or correct grammar per the assessed proficiency of the user. This would supplement a teacher or parent&rsquo;s instructions while still being engaging to the child.&nbsp;</span></p> <br /> <p dir="ltr"><span>Establishing protocols</span><span>. Protocols were established for data storage, access, curation, and utilization. A cloud computing environment was created to facilitate these processes. Using this, data was prepared, analyzed, and utilized for training purposes.</span></p> <br /> <p dir="ltr"><span>Training an analysis tool</span><span>. The biggest challenges faced by the team were a lack of properly annotated dialogue-based datasets for children, no datasets providing reliable developmental labels for child speech, and poor performance of available diarization technology for child speakers. The CHILDES dataset was found to provide a wealth of transcribed dialogues between children and parents or therapists, but it was lacking in development metric labels. The original developmental metric of interest was Brown&rsquo;s Stages, but the metric was changed to IPSyn scoring due to the latter&rsquo;s more robust analysis of syntax and morphology. A customized IPSyn scoring algorithm was developed to be used in conjunction with the CHILDES data to address the second challenge. In order to address the challenge of child speech diarization, a custom diarization algorithm was created and trained using audio from both normal and speech impared children. In order to assess accuracy, a custom benchmarking dataset was created using the </span><span>Prodigy</span><span> annotation to label dialogues between children and adults. Audio for this dataset was chosen for clarity as well as gender and age heterogeneity.&nbsp;</span></p> <br /> <p dir="ltr"><span>Construction of the recommendation algorithm.</span><span> The original goal of the recommendation engine was to provide feedback directly to the child based on their developmental level. While evaluating the use of IPSyn scores without the specificity of individual rules, we investigated recommendations based on speech from children of a higher IPSyn score such as 10 points higher than the user child. Here we pivoted again to instead provide recommendations to clinicians and parents based on feedback from experts in the field. It was decided that the specific IPSyn rules triggered would be provided to parents or clinicians as insight for what is needed in the developmental track of the child. A social function detection algorithm was also developed based on the dialogue observed between children and adults. The social functions detected include questions, comments, requests, commands, and refusals. A recommendation report that included both the IPSyn rules and detected social functions was the final outcome of the recommendation goal.&nbsp;</span></p> <br /> <p dir="ltr"><span>The main accomplishments of this Phase I SBIR focused on the dataset and our algorithm. We have created a child-specific dataset that now has the potential for benchmarking in the field of diarization -- the first of its kind. We have leveraged this to make strides in child-specific diarization capabilities for our algorithm. We have also developed programmatic IPSyn rules, opening the possibility for more automated metrics of language development. This addressed a common pain point that we repeatedly encountered in our customer discovery research: clinicians&rsquo; need for an automated, time-efficient, and accurate language development metric system. There is also a large research and development gap in the detection of the social function of speech from text dialogue. While several technologies can detect and caption speech, few engines are capable of processing and categorizing the function of utterances. This feature will allow our algorithm to assess how each participant is using language to communicate with each other, or not. More importantly, this feature could help detect social-environmental factors that contribute to MLU length, syntax complexity, and social function application.&nbsp;</span></p> <br /> <p dir="ltr"><span>With the help of the NSF, iTherapy is proud to have created one of the first, if not the first, algorithm to integrate state-of-the-art speech-to-text diarization, IPSyn scoring, and social function detection to enable mobile automation of speech and language assessment in addition to social function measurement.</span></p> </span></p><br> <p>            Last Modified: 06/10/2021<br>      Modified by: Lois&nbsp;J&nbsp;Brady</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623358749412_NSF_1--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623358749412_NSF_1--rgov-800width.jpg" title="Diarization Machine Learning Algorithm"><img src="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623358749412_NSF_1--rgov-66x44.jpg" alt="Diarization Machine Learning Algorithm"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 1: Flow of Diarization Machine Learning Algorithm</div> <div class="imageCredit">David Baugher</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Lois&nbsp;J&nbsp;Brady</div> <div class="imageTitle">Diarization Machine Learning Algorithm</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623358888025_NSF_2--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623358888025_NSF_2--rgov-800width.jpg" title="Diarization Output Comparison"><img src="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623358888025_NSF_2--rgov-66x44.jpg" alt="Diarization Output Comparison"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 2: Example of Diarization Output Comparison</div> <div class="imageCredit">David Baugher</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Lois&nbsp;J&nbsp;Brady</div> <div class="imageTitle">Diarization Output Comparison</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623359118410_NSF_4--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623359118410_NSF_4--rgov-800width.jpg" title="EASI-AS Algorithm Pipeline"><img src="/por/images/Reports/POR/2021/2025836/2025836_10703653_1623359118410_NSF_4--rgov-66x44.jpg" alt="EASI-AS Algorithm Pipeline"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 3: Flowchart of EASI-AS Algorithm Pipeline</div> <div class="imageCredit">David Baugher</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Lois&nbsp;J&nbsp;Brady</div> <div class="imageTitle">EASI-AS Algorithm Pipeline</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Autism Spectrum Disorder (ASD) is a neurodevelopmental communication disorder affecting over 3.5 million Americans that results in functional language delays and behavioral challenges. These delays often result in limited speech and increased communication difficulties -- approximately 40% of people in the ASD population are minimally verbal or non-verbal, having increased communication challenges. While many technologies and teaching tools have surfaced to assess the needs of non-verbal children with ASD, these often rely on the physical presence of a Speech Language Pathologist, teacher, or parent. This creates a sizable bottleneck for those with ASD to further learn and practice language skills.    It was the goal of this SBIR Phase I to explore the feasibility of an AI Language Coach for non-verbal or minimally verbal children with ASD. The main objectives of this 12-month project were to establish the protocols for data collection and processing, train an analysis tool to assess user proficiency, and construct a pilot recommendation engine. The original end goal for this project was to create an AI algorithm that recommended alternate phrases or correct grammar per the assessed proficiency of the user. This would supplement a teacher or parent’s instructions while still being engaging to the child.    Establishing protocols. Protocols were established for data storage, access, curation, and utilization. A cloud computing environment was created to facilitate these processes. Using this, data was prepared, analyzed, and utilized for training purposes.   Training an analysis tool. The biggest challenges faced by the team were a lack of properly annotated dialogue-based datasets for children, no datasets providing reliable developmental labels for child speech, and poor performance of available diarization technology for child speakers. The CHILDES dataset was found to provide a wealth of transcribed dialogues between children and parents or therapists, but it was lacking in development metric labels. The original developmental metric of interest was Brown’s Stages, but the metric was changed to IPSyn scoring due to the latter’s more robust analysis of syntax and morphology. A customized IPSyn scoring algorithm was developed to be used in conjunction with the CHILDES data to address the second challenge. In order to address the challenge of child speech diarization, a custom diarization algorithm was created and trained using audio from both normal and speech impared children. In order to assess accuracy, a custom benchmarking dataset was created using the Prodigy annotation to label dialogues between children and adults. Audio for this dataset was chosen for clarity as well as gender and age heterogeneity.    Construction of the recommendation algorithm. The original goal of the recommendation engine was to provide feedback directly to the child based on their developmental level. While evaluating the use of IPSyn scores without the specificity of individual rules, we investigated recommendations based on speech from children of a higher IPSyn score such as 10 points higher than the user child. Here we pivoted again to instead provide recommendations to clinicians and parents based on feedback from experts in the field. It was decided that the specific IPSyn rules triggered would be provided to parents or clinicians as insight for what is needed in the developmental track of the child. A social function detection algorithm was also developed based on the dialogue observed between children and adults. The social functions detected include questions, comments, requests, commands, and refusals. A recommendation report that included both the IPSyn rules and detected social functions was the final outcome of the recommendation goal.    The main accomplishments of this Phase I SBIR focused on the dataset and our algorithm. We have created a child-specific dataset that now has the potential for benchmarking in the field of diarization -- the first of its kind. We have leveraged this to make strides in child-specific diarization capabilities for our algorithm. We have also developed programmatic IPSyn rules, opening the possibility for more automated metrics of language development. This addressed a common pain point that we repeatedly encountered in our customer discovery research: clinicians’ need for an automated, time-efficient, and accurate language development metric system. There is also a large research and development gap in the detection of the social function of speech from text dialogue. While several technologies can detect and caption speech, few engines are capable of processing and categorizing the function of utterances. This feature will allow our algorithm to assess how each participant is using language to communicate with each other, or not. More importantly, this feature could help detect social-environmental factors that contribute to MLU length, syntax complexity, and social function application.    With the help of the NSF, iTherapy is proud to have created one of the first, if not the first, algorithm to integrate state-of-the-art speech-to-text diarization, IPSyn scoring, and social function detection to enable mobile automation of speech and language assessment in addition to social function measurement.        Last Modified: 06/10/2021       Submitted by: Lois J Brady]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
