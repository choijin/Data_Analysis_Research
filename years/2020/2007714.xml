<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Compression for Learning over networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>523925.00</AwardTotalIntnAmount>
<AwardAmount>523925</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Armand Makowski</SignBlockName>
<PO_EMAI>amakowsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928910</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Data compression is a core component of all communication protocols, as it can translate to bandwidth savings, energy efficiency and low delay operations. In the traditional setup, an information source compresses its messages so that they can be communicated efficiently with the goal of ensuring accurate reconstruction at the destination. This project seeks to design compression schemes that are specifically tailored to Machine Learning applications: If the transmitted messages support a given learning task (e.g., classification or learning), the desired compression schemes should provide better support for the learning task instead of focusing on reconstruction accuracy. This approach to compression could potentially yield significant benefits in terms of communication efficiency, while simultaneously promoting the successful implementation of Machine Learning algorithms. By improving communication efficiency, such schemes are expected to  contribute to the successful implementation  of distributed machine learning algorithms over networks.&lt;br/&gt;&lt;br/&gt;Traditionally, compression schemes are evaluated using rate-distortion trade-offs; this project is interested in rate-accuracy trade-offs, where accuracy captures the effect that quantization may have on a specific machine learning task. There is particular interest in information-theoretic lower bounds and trade-offs, and in explicit compression for the following two questions: (1) How to compress for model training, when we need to use distributed communication constrained nodes to learn a model, fast and efficiently; and (2) How to compress for communication during inference. The project will derive bounds and algorithms for distributed compression of features coming from composite distributions that will be used for a machine learning task, such as classification.  This work will advance the state of the art, and  build new connections between the areas of data compression and distributed machine learning.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/30/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/30/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007714</AwardID>
<Investigator>
<FirstName>Suhas</FirstName>
<LastName>Diggavi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Suhas Diggavi</PI_FULL_NAME>
<EmailAddress>suhas@ee.ucla.edu</EmailAddress>
<PI_PHON>3102065171</PI_PHON>
<NSF_ID>000550026</NSF_ID>
<StartDate>07/30/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Christina</FirstName>
<LastName>Fragouli</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christina Fragouli</PI_FULL_NAME>
<EmailAddress>christina.fragouli@ucla.edu</EmailAddress>
<PI_PHON>3102068795</PI_PHON>
<NSF_ID>000637237</NSF_ID>
<StartDate>07/30/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Los Angeles]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951406</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>2878</Code>
<Text>SPECIAL PROJECTS - CCF</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~523925</FUND_OBLG>
</Award>
</rootTag>
