<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Modeling Pre- and Post- Conditions for Understanding Events</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>407747.00</AwardTotalIntnAmount>
<AwardAmount>407747</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project develops new algorithms for learning the typical pre-conditions and post-conditions of real-world events. These logical conditions are crucial for developing better language understanding applications that can reason precisely about situations described in written text. There have been significant technological advances in the automatic understanding of text, but event reasoning requires knowledge that is often unstated and implicit. For example, if a meeting is canceled, it would be unusual for the text to say that the meeting was scheduled to happen (a pre-condition), and that it will now no longer happen (a post-condition). While these are obvious to a human, these conditions are unknown and crucial to building assistive technology. This kind of reasoning can enable complete document understanding, support precise and explainable question answering, and improve the output of language generation. This project has broad applications to a variety of assistive technology for information access and understanding for the general public. Learning pre-conditions can further educational text exploration applications by explaining how a certain situation came about. Better language understanding can also help explain automated decisions, making technology more trustworthy in mission critical domains. And finally, this project will help address the shortage of talent in the critical areas of computer science and machine learning by training graduate and undergraduate students.&lt;br/&gt; &lt;br/&gt;This project focuses on developing both the models to learn pre- and post-condition relations, but also the large datasets required to enable this learning. The first thrust in the project plan is to develop new datasets of conditional knowledge, and then to develop initial supervised learning algorithms to detect them in text. The project will initially focus on todayâ€™s large-scale language models to establish competitive baselines that the rest of the project will improve upon. After creating these annotated datasets and baselines, the focus will then turn to developing generative neural architectures like variational autoencoders that are augmented with rich structured latent spaces. These spaces will be augmented with entity networks that allow it to track generic event knowledge, but also specific knowledge about the entities. The motivation for generative models is to aggregate condition knowledge from large collections of unlabeled text as well. Finally, in addition to developing large scale datasets to learn this knowledge, the project will develop new reasoning tasks that could spur the community to develop more precise language understanding models, and to use these tasks to further research into richer models of event knowledge. All scientific findings, datasets, and other artifacts of the research will be made available for the scientific community and the broader public.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/17/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007290</AwardID>
<Investigator>
<FirstName>Niranjan</FirstName>
<LastName>Balasubramanian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Niranjan Balasubramanian</PI_FULL_NAME>
<EmailAddress>niranjan@cs.stonybrook.edu</EmailAddress>
<PI_PHON>6316328471</PI_PHON>
<NSF_ID>000678413</NSF_ID>
<StartDate>08/17/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stony Brook University]]></Name>
<CityName>Stony Brook</CityName>
<StateCode>NY</StateCode>
<ZipCode>117944400</ZipCode>
<StreetAddress><![CDATA[Department of Computer Science]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~253882</FUND_OBLG>
<FUND_OBLG>2021~153865</FUND_OBLG>
</Award>
</rootTag>
