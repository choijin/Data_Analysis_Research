<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  COVID-19 Cough Classifier Using Artificial Intelligence</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>02/28/2021</AwardExpirationDate>
<AwardTotalIntnAmount>255974.00</AwardTotalIntnAmount>
<AwardAmount>255974</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alastair Monk</SignBlockName>
<PO_EMAI>amonk@nsf.gov</PO_EMAI>
<PO_PHON>7032924392</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to develop a COVID-19 diagnostic tool using artificial intelligence.  The proposed Cough Detector and Cough Classifier is able to “listen” to sounds in a given environment, then detects and classifies coughs.  When a cough related to COVID-19 is identified, the individual and relevant personnel in a potential germ circle can be immediately notified. Functioning as an early warning system, the tool will work on a mobile device or laptop, and can be embedded in other technology, such as infrared cameras with microphones or other sound detection equipment. The tool will support ongoing outbreaks and mitigation of social distancing considerations. &lt;br/&gt; &lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will utilize deep learning and transfer learning to develop a COVID-19 cough classifier. The unique features of a COVID-19 cough require distinguishing between characteristics of widened airway, narrowed airway, fluid filled air sacs, airflow patterns of spirometry, stiff lungs, and others. The unique characteristics or features are learned while classify cough types on a training data set. A tuned deep learning model is able to distinguish COVID-19 cough from other types of cough in real-time.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/09/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2029591</AwardID>
<Investigator>
<FirstName>Catherine</FirstName>
<LastName>Kolding</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Catherine M Kolding</PI_FULL_NAME>
<EmailAddress>kittykolding@gmail.com</EmailAddress>
<PI_PHON>3039168112</PI_PHON>
<NSF_ID>000825258</NSF_ID>
<StartDate>09/09/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>COVID COUGH INC</Name>
<CityName>GREENWOOD VILLAGE</CityName>
<ZipCode>801115075</ZipCode>
<PhoneNumber>3039168112</PhoneNumber>
<StreetAddress>6400 S FIDDLERS GREEN CIR STE 25</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>117469505</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COVID COUGH INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[COVID COUGH INC]]></Name>
<CityName>Greenwood Village</CityName>
<StateCode>CO</StateCode>
<ZipCode>801114950</ZipCode>
<StreetAddress><![CDATA[6400 S Fiddlers Green, Ste 250]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>066E</Code>
<Text>INSTRUMENTATION &amp; DIAGNOSTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>096Z</Code>
<Text>COVID-19 Research</Text>
</ProgramReference>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~255974</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The overarching aim of this project was to provide a solution for screening large, diverse populations for COVID-19.&nbsp; Key to achieving this goal was the development of a training dataset from which an artificial intelligence/machine learning (AI/ML) engine could learn to identify COVID-19 from a forced cough vocalization. Exploring a wide variety of potential architectures for construction of this AI/ML engine was the first objective. Among the models evaluated and tested were CNN, BiRNN, BiGRU, BiLSTMs, and CapsNet.</p> <p>Online cough libraries were explored and tested to determine the requirements of a COVID-19 cough vocalization AI/ML training dataset.&nbsp; Expansion of this reference base was accomplished by collecting recorded cough vocalization data from study participants presenting for COVID-19 testing at our clinical partner sites.&nbsp; Each cough vocalization yielded a unique signal data signature that was then adjudicated by an audio engineer. Feature engineering was also used to improve the sound quality and reduce background noise, creating an ideal learning environment for the AI/ML signal data signature classifiers. Through a process of serially removing extraneous noise, our audio engineer developed sound perspectives that were used to train the neural networks. This allowed for identification of the isolated cough vocalization even when background noise was present, increasing the sensitivity and specificity of the device and making it more suitable to a real world clinical setting. The next objective was to perform an exploratory analysis of the COVID-19 cough dataset.&nbsp; Of the high-fidelity sound signal recordings, 76 were obtained from patients with a positive COVID-19 PCR and 75 were obtained from patients with a negative COVID-19 PCR.&nbsp; The highest quality recordings in the population were used to create a reference library and develop powerful deep learning neural networks that demonstrate solid benchtop performance at classifying COVID-19 vs. non-COVID-19 samples.</p> <p>The intellectual merit of our project resulted in laying the foundation for the design and development of a scalable, low cost, real-time diagnostic test for COVID-19.&nbsp; Expanding cough vocalization analyses to the diagnosis of COVID-19 required high fidelity sound data led to the development of an audio engineered process to achieve a high quality dataset for AI/ML deep learning. And once completed and refined, the impact of this new COVID-19 diagnostic software will increase the effectiveness and efficiency our healthcare workforce and reduce disparities in healthcare.</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/01/2021<br>      Modified by: Catherine&nbsp;M&nbsp;Kolding</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The overarching aim of this project was to provide a solution for screening large, diverse populations for COVID-19.  Key to achieving this goal was the development of a training dataset from which an artificial intelligence/machine learning (AI/ML) engine could learn to identify COVID-19 from a forced cough vocalization. Exploring a wide variety of potential architectures for construction of this AI/ML engine was the first objective. Among the models evaluated and tested were CNN, BiRNN, BiGRU, BiLSTMs, and CapsNet.  Online cough libraries were explored and tested to determine the requirements of a COVID-19 cough vocalization AI/ML training dataset.  Expansion of this reference base was accomplished by collecting recorded cough vocalization data from study participants presenting for COVID-19 testing at our clinical partner sites.  Each cough vocalization yielded a unique signal data signature that was then adjudicated by an audio engineer. Feature engineering was also used to improve the sound quality and reduce background noise, creating an ideal learning environment for the AI/ML signal data signature classifiers. Through a process of serially removing extraneous noise, our audio engineer developed sound perspectives that were used to train the neural networks. This allowed for identification of the isolated cough vocalization even when background noise was present, increasing the sensitivity and specificity of the device and making it more suitable to a real world clinical setting. The next objective was to perform an exploratory analysis of the COVID-19 cough dataset.  Of the high-fidelity sound signal recordings, 76 were obtained from patients with a positive COVID-19 PCR and 75 were obtained from patients with a negative COVID-19 PCR.  The highest quality recordings in the population were used to create a reference library and develop powerful deep learning neural networks that demonstrate solid benchtop performance at classifying COVID-19 vs. non-COVID-19 samples.  The intellectual merit of our project resulted in laying the foundation for the design and development of a scalable, low cost, real-time diagnostic test for COVID-19.  Expanding cough vocalization analyses to the diagnosis of COVID-19 required high fidelity sound data led to the development of an audio engineered process to achieve a high quality dataset for AI/ML deep learning. And once completed and refined, the impact of this new COVID-19 diagnostic software will increase the effectiveness and efficiency our healthcare workforce and reduce disparities in healthcare.          Last Modified: 04/01/2021       Submitted by: Catherine M Kolding]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
