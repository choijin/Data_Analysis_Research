<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Scalable Algorithms for Bayesian On-Line Learning with Large-Scale Dynamic Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Pena Edsel</SignBlockName>
<PO_EMAI>epena@nsf.gov</PO_EMAI>
<PO_PHON>7032928080</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Bayesian methods provide a principled way for assessing model uncertainty in machine learning of big data, which is critical to the development of trustworthy artificial intelligence (AI). However, the lack of efficient Monte Carlo algorithms has drastically hindered applications of Bayesian methods in the big data era. Compared to frequentist methods, Bayesian methods are often much slower. To tackle this difficulty, a variety of scalable Monte Carlo algorithms have been developed in the recent literature. However, these algorithms can only be applied to static data; none of them can be directly applied to dynamic data.  Many of the problems centering data science, such as natural language processing, autonomous car driving and weather forecasting, are facing challenges of dynamic data. The traditional particle filters or sequential Monte Carlo algorithms lack the scalability necessary for dealing with large-scale dynamic data. By reformulating the ensemble Kalman filter (EnKF) under the framework of Langevin dynamics, this project proposes Langevinized EnKF as a general and scalable stochastic gradient sequential Monte Carlo algorithm for Bayesian on-line learning with large-scale dynamic data. The Langevinized EnKF improves uncertainty quantification for a wide class of data assimilation problems, advancing the development of trustworthy AI. Successful completion of this project will generate a set of scalable and theoretically rigorous algorithms for Bayesian on-line learning, which can provide significant benefits to the development of data driven technologies. The research results will be disseminated to communities of interest via collaborations, publications, and conference presentations. The project will also have significant impacts on education through direct involvement of graduate students and incorporation of the research results into undergraduate and graduate courses. &lt;br/&gt;&lt;br/&gt;Although the EnKF has been extremely successful in dealing with complex dynamic data encountered in  oceanography, reservoir modeling and weather forecasting, it does not converge to the right filtering distribution except for linear systems in the large ensemble limit. The Langevinized EnKF resolves this issue; it converges to the right filtering distribution in data assimilation and is thus able to quantify uncertainty of the underlying dynamic system. The Langevinized EnKF can also be used for Bayesian learning with large-scale statistic data by reformulating the Bayesian inverse problem as a state-space model with Langevin dynamics and the subsampling technique. Different variants of the Langevinized EnKF will be developed to extend its applications to non-Gaussian data and incomplete data. As the whole, this project will provide a complete treatment for Bayesian analysis of big data. The Langevinized EnKF can be applied to big data problems in various data scenarios: dynamic data and static data, Gaussian data and non-Gaussian data, and complete data and incomplete data,  provided the data is classified in different ways. Statistical theory underlying the Langevinized EnKF will be rigorously studied. Exciting scientific applications, including language modeling and dynamic network analysis, will be conducted.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/20/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/20/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2015498</AwardID>
<Investigator>
<FirstName>Faming</FirstName>
<LastName>Liang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Faming Liang</PI_FULL_NAME>
<EmailAddress>fmliang@purdue.edu</EmailAddress>
<PI_PHON>7654944452</PI_PHON>
<NSF_ID>000490214</NSF_ID>
<StartDate>06/20/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[PURDUE UNIVERSITY]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072114</ZipCode>
<StreetAddress><![CDATA[250 N. University St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>059Z</Code>
<Text>Science of Learning</Text>
</ProgramReference>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~250000</FUND_OBLG>
</Award>
</rootTag>
