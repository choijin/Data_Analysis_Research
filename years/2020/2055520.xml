<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CNS Core: Medium: Collaborative: Reality-Aware Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>199942.00</AwardTotalIntnAmount>
<AwardAmount>141739</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alexander Sprintson</SignBlockName>
<PO_EMAI>asprints@nsf.gov</PO_EMAI>
<PO_PHON>7032922170</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project seeks to improve the robustness of wireless sensing and networking technologies through a reality-aware wireless architecture that blends networking and sensing. Robust perception and high-bandwidth networking benefit innovations across a diverse spectrum of high-impact areas including mixed-reality, robotics, and automated vehicles. For example, the use of such techniques to enhance driver assistance systems or automated vehicles has the potential to save numerous lives. In addition to disseminating results through scholarly publication, the project will engage the wireless and automotive industry to facilitate the technology transfer. The project also includes a set of integrated education and broadening participation activities to engage and retain students from underrepresented groups through internship programs, educational and outreach activities at each participating institution.&lt;br/&gt;&lt;br/&gt;As wireless sensing and networking technologies make significant strides in today's world, applications such as automated driving or augmented reality are increasingly involving rich sensing of the environment with unprecedented network requirements. Existing approaches that strictly separate the network stack and the perception component face challenges in providing robust perception and high-bandwidth networking. To address this, this project develops and studies a reality-aware wireless architecture that blends networking and sensing components, rather than isolating them. This approach exploits sensor information and scene geometry to provide improved and more predictable wireless network performance. It also uses information received over the network to aid perception functions such as object recognition and point correspondence. The team first explores the design space of network architectures for blending perception and communications by designing low-energy tags and visual signaling strategies. The team then develops simultaneous localization and mapping algorithms that blend conventional strategies with network information to enhance robustness. It also designs geometric matching techniques to enhance object association in images with network information. At the network and link layers, the system will exploit knowledge about physical obstacles and the surrounding geometry obtained from camera views and other sensors to provide more predictable and seamless high-bandwidth coverage. The outcomes from the thrusts are integrated into a reality-aware network architecture that exploits information about the environment gathered via sensors. The architecture is implemented and evaluated in indoor and outdoor experiments, culminating in a validation on the Platform for Advanced Wireless Research (PAWR) COSMOS testbed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/05/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/11/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2055520</AwardID>
<Investigator>
<FirstName>Shubham</FirstName>
<LastName>Jain</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shubham Jain</PI_FULL_NAME>
<EmailAddress>jain@cs.stonybrook.edu</EmailAddress>
<PI_PHON>5105054789</PI_PHON>
<NSF_ID>000757699</NSF_ID>
<StartDate>02/05/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName>Stony Brook</CityName>
<StateCode>NY</StateCode>
<ZipCode>117940001</ZipCode>
<StreetAddress><![CDATA[West 5510 FRK Mel Lib]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~42547</FUND_OBLG>
<FUND_OBLG>2020~49510</FUND_OBLG>
<FUND_OBLG>2021~49682</FUND_OBLG>
</Award>
</rootTag>
