<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: PPoSS: Planning: Hardware-accelerated Trustworthy Deep Neural Network</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>70000.00</AwardTotalIntnAmount>
<AwardAmount>70000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yuanyuan Yang</SignBlockName>
<PO_EMAI>yyang@nsf.gov</PO_EMAI>
<PO_PHON>7032928067</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Deep-learning approaches have recently achieved much higher accuracy than traditional machine-learning approaches in various applications (e.g., computer vision, virtual/augmented reality, and natural language processing). Existing research has shown that large-scale data from various sources with high-resolution sensing or large-volume data-collection capabilities can significantly improve the performance of deep-learning approaches. However, state-of-the-art hardware and software cannot provide sufficient computing capabilities and resources to ensure accurate deep-learning performance in a timely manner when using extremely large-scale data. This project develops a scalable and robust heterogeneous system that includes a new low-cost, secure, deep-learning hardware-accelerator architecture and a suite of large-data-compatible deep-learning algorithms. It allows deep learning to fully benefit from extremely large-scale data and facilitates efficient, low-latency applications in connected vehicles, real-time mobile applications, and timely precision health. The new technologies resulting from this project can enable more research opportunities to design new hardware accelerators for deep learning and obtain further optimization in computational complexity and reduction in power consumption. Moreover, by integrating the research results with the undergraduate and graduate curricula and outreach activities, this project has great impacts on education and training of researchers and engineers for computer architecture, security, theory and algorithms, and systems.&lt;br/&gt;&lt;br/&gt;This project designs trustworthy hardware accelerators optimized for large-scale deep-learning computations and models the complicated structure of large-scale datasets. More specifically, this project develops a novel hardware accelerator for deep learning that can achieve low power consumption. In addition, this project designs innovative in-memory encryption schemes to secure the neural models in deep-learning accelerators. Furthermore, data-modeling and statistical-learning algorithms are developed in this project to further reduce the computing cost of deep learning when processing extremely large-scale datasets. Finally, this project builds and evaluates a prototype of the proposed heterogeneous deep-learning system in terms of efficiency, scalability, and security in multiple application domains including mobile applications, connected vehicles and precision health.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/07/2020</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2028876</AwardID>
<Investigator>
<FirstName>Yingying</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yingying Chen</PI_FULL_NAME>
<EmailAddress>yingche@scarletmail.rutgers.edu</EmailAddress>
<PI_PHON>7325471247</PI_PHON>
<NSF_ID>000080615</NSF_ID>
<StartDate>08/07/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName/>
<StateCode>NJ</StateCode>
<ZipCode>088543925</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>042Y</Code>
<Text>PPoSS-PP of Scalable Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>026Z</Code>
<Text>NSCI: National Strategic Computing Initi</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~70000</FUND_OBLG>
</Award>
</rootTag>
