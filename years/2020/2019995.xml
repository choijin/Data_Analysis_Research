<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>The profile of feature-based attention: A new framework</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>434706.00</AwardTotalIntnAmount>
<AwardAmount>434706</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Daily life requires us to navigate an environment that contains much more information than the brain can process at once. Using attention, we can process information that is relevant to the task while ignoring information that is irrelevant to the task. One key component of this type of selective attention is based on feature information. For example, when keeping track of our child at the shopping mall we may focus on the color of the child’s clothing. However, in so doing, we are not completely unaware of other aspects of the environment. How does attention to a particular feature impact the processing of the relevant and irrelevant features? Classical studies have supported simple models based on feature similarity, while more recent work has demonstrated more complex relationships among the features. In the present project, the investigator uses a cross-disciplinary approach that integrates methods from psychophysics, computational modeling, and neuroimaging in order to understand the cognitive and neural aspects of an attentional mechanism called “surround suppression,” in which the processing of features near the attentional target is weakened. A better understanding of this type of attentional mechanism will have implications for many situations in which humans use visual input to guide behavior, such as education, communication, and human factors engineering. The research project will also provide interdisciplinary training opportunities for graduate and undergraduate students in brain and cognitive sciences.&lt;br/&gt;&lt;br/&gt;The investigator team will conduct behavioral and neuroimaging experiments to examine the mechanisms underlying the attentional profile. There are three interrelated objectives. First, the investigators will examine how the attentional profile for simple features changes with stimulus context and task demand. To map out the attentional profile, participants are instructed to attend to a feature to perform a target-detection task while the target feature is systematically varied. Second, the investigators will measure the attentional profile for visual objects defined by the conjunction of two features and examine its sensitivity to task demands. In these experiments, the general hypothesis is that the attentional profile can be flexibly adjusted based on stimulus context and task demand, allowing efficient selection of task-relevant information. In the third objective, the investigators will use functional magnetic resonance imaging to measure neural activity while human participants are engaged in the feature-attention task.  Model-based neuroimaging analyses will be used to distinguish between two possible neural mechanisms that can cause attention-induced surround suppression.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/04/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/20/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2019995</AwardID>
<Investigator>
<FirstName>Taosheng</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Taosheng Liu</PI_FULL_NAME>
<EmailAddress>tsliu@msu.edu</EmailAddress>
<PI_PHON>5174326694</PI_PHON>
<NSF_ID>000516533</NSF_ID>
<StartDate>09/04/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName>East Lansing</CityName>
<StateCode>MI</StateCode>
<ZipCode>488951116</ZipCode>
<StreetAddress><![CDATA[316 Physics Rd., Room 289A]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~434706</FUND_OBLG>
</Award>
</rootTag>
