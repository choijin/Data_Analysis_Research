<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: A Novel Framework for Informed Manipulation Planning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>425000.00</AwardTotalIntnAmount>
<AwardAmount>425000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Humans use many types of manipulation to accomplish daily tasks and easily sequence and execute pertinent actions. Robots are confined to very simple tasks that are often painstakingly broken down to an excruciating level of detail by humans who operate those robots. Today, more than ever, there is an urgent need to develop robots that reason about manipulation as seamlessly as humans do. Manipulation planning finds a sequence of actions that move the robot and the objects it interacts with from a start state to a goal state. In doing so, contacts are formed and broken, limits are imposed, and some high-level reasoning occurs:. Grasping, placing, regrasping, and rearranging objects often take place. The combination of manipulation planning with classical AI planning and formal methods will lead to the kind of behavior that is expected from a robot capable of cleaning a hospital room, performing tasks in an ICU, or assisting a recovering patient.&lt;br/&gt;&lt;br/&gt;This project advocates a novel, unifying framework for manipulation planning. It adopts a constraint-centric view, in particular using manifold constraints which define lower-dimensional subspaces, or modes, among which the robot must transition. The definition of transitions is also constraint-centric, defined by the combination of the constraints which define modes, and is only possible within the unified approach used to consider modes. The work depends on constructs from differential geometry and the use of multi-resolution search schemes. First, the project will generalize sampling-based algorithms for robot motion planning by decoupling the planning strategy from the satisfaction of constraints often found in manipulation. Second, the concept of a transition graph between modes will be defined and exploited during search to automatically find viable transitions between modes and produce manipulation plans. The work will start with a specific but general type of constraint, manifold constraints, and later expand to other types. The proposed research will investigate optimality and robustness guarantees provided by the proposed framework and will identify the limits of using constraints as a unifying construct in manipulation planning. The work will be supported by extensive experimentation in both simulation and realistic scenarios that involve several objects, cabinets, shelves, a mobile manipulator, and two stationary state-of-the-art manipulators.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/14/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2008720</AwardID>
<Investigator>
<FirstName>Lydia</FirstName>
<LastName>Kavraki</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lydia Kavraki</PI_FULL_NAME>
<EmailAddress>kavraki@cs.rice.edu</EmailAddress>
<PI_PHON>7133484834</PI_PHON>
<NSF_ID>000489055</NSF_ID>
<StartDate>09/14/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050299031</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WILLIAM MARSH RICE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050299031</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[William Marsh Rice University]]></Name>
<CityName/>
<StateCode>TX</StateCode>
<ZipCode>770051827</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~425000</FUND_OBLG>
</Award>
</rootTag>
