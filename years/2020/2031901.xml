<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: CPR-COVID-19 Prevention Robot in Dense Areas</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2020</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>120000.00</AwardTotalIntnAmount>
<AwardAmount>120000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Erion Plaku</SignBlockName>
<PO_EMAI>eplaku@nsf.gov</PO_EMAI>
<PO_PHON>7032928695</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Motivated by the COVID-19 pandemic, this project will develop a robot to understand whether pedestrians in public places or offices are maintaining social distancing guidelines. The project will develop new methods that leverage machine learning, computer vision, and robot motion planning to ascertain the positions of pedestrians as they move in a confined area. Real-time understanding of pedestrian movements can assist social distancing efforts, minimizing the spread of COVID-19, and can more broadly enhance human-robot interactions.&lt;br/&gt;&lt;br/&gt;The underlying challenges include development of new navigation algorithms that can compute collision-free paths for a robot in medium and high-density crowds. Navigation among pedestrians will be formulated as a Partially-Observable Markov Decision Process and solved using deep reinforcement learning, particularly focusing on Proximal Policy Optimization. The pedestrian-tracking approach will be based on a novel concept of Frontal Reciprocal Velocity Obstacles, which uses an elliptical approximation of each pedestrian motion and estimates the underlying dynamics by considering intermediate goals and collision avoidance. The planned approach will also be able to handle occlusions among pedestrians by moving the robot in an intelligent way to improve the information that it receives from its sensors. The project will use commodity sensors, including cameras and 2D LIDARs, to understand pedestrian movements and check for social distance constraints. Finally, this project will investigate techniques to influence pedestrian behavior using robots.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/10/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2031901</AwardID>
<Investigator>
<FirstName>Dinesh</FirstName>
<LastName>Manocha</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dinesh Manocha</PI_FULL_NAME>
<EmailAddress>dm@cs.umd.edu</EmailAddress>
<PI_PHON>9192184986</PI_PHON>
<NSF_ID>000291378</NSF_ID>
<StartDate>06/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Aniket</FirstName>
<LastName>Bera</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Aniket Bera</PI_FULL_NAME>
<EmailAddress>ab@cs.umd.edu</EmailAddress>
<PI_PHON>3014054209</PI_PHON>
<NSF_ID>000812661</NSF_ID>
<StartDate>06/10/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~120000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our main contributions in this work are:</p> <p>1. A mobile robot system that detects breaches in social distancing norms, autonomously navigates towards groups of non-compliant people and encourages them to maintain at least 6 feet of distance. We demonstrate that our mobile robot monitoring system is effective in terms of detecting social distancing breaches in static indoor scenes and can enforce social distancing in all of the detected breaches. Furthermore, our method does not require humans to wear any tracking or wearable devices.</p> <p>&nbsp;</p> <p>2. We also integrated a CCTV setup in indoor scenes (if available) with the COVID-robot to further increase the area being monitored and improve the accuracy of tracking and pursuing dynamic non-compliant pedestrians. This hybrid combination of statically mounted cameras and a mobile robot can further improve the number of breaches detected and enforcements by up to 100%.</p> <p>&nbsp;</p> <p>3. We presented a novel real-time method to estimate distances between people in images captured using an RGB-D camera on the robot and CCTV camera using a homography transformation. The distance estimate has an average error of 0.3 feet in indoor environments.</p> <p>&nbsp;</p> <p>4. We also presented a novel algorithm for classifying noncompliant people into different groups and selecting a goal that makes the robot move to the vicinity of the largest group and enforce social distancing norms.</p> <p>&nbsp;</p> <p>5. We integrated a thermal camera with the robot and wirelessly transmit the thermal images to appropriate security/healthcare personnel. The robot does not record temperatures or perform any form of person recognition to protect people?s privacy.</p> <p>&nbsp;</p> <p>We have evaluated our method quantitatively in terms of the accuracy of localizing a pedestrian, the number of social distancing breaches detected in static and mobile pedestrians, and our CCTV-robot hybrid system. We also measure the time duration for which the robot can track a dynamic pedestrian. Qualitatively, we highlight the trajectories of the robot pursuing dynamic pedestrians when using only its RGB-D sensor as compared to when both the CCTV and RGB-D cameras are used.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/04/2021<br>      Modified by: Aniket&nbsp;Bera</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841577968_Fig1--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841577968_Fig1--rgov-800width.jpg" title="CPR Robot"><img src="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841577968_Fig1--rgov-66x44.jpg" alt="CPR Robot"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our robot detecting non-compliance to social distancing norms, classifying non-compliant pedestrians into groups and autonomously navigating to the group with currently the most people in it (a group with 3 people in this scenario).</div> <div class="imageCredit">UMD</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Aniket&nbsp;Bera</div> <div class="imageTitle">CPR Robot</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841619240_Fig2--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841619240_Fig2--rgov-800width.jpg" title="CPR Robot 2"><img src="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841619240_Fig2--rgov-66x44.jpg" alt="CPR Robot 2"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The criteria used to detect whether two pedestrians violate the social distance constraint.</div> <div class="imageCredit">UMD</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Aniket&nbsp;Bera</div> <div class="imageTitle">CPR Robot 2</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841662793_Fig3--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841662793_Fig3--rgov-800width.jpg" title="CPR Robot 3"><img src="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841662793_Fig3--rgov-66x44.jpg" alt="CPR Robot 3"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Overall architecture of COVID-Robot and social distance monitoring</div> <div class="imageCredit">UMD</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Aniket&nbsp;Bera</div> <div class="imageTitle">CPR Robot 3</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841715157_Fig5--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841715157_Fig5--rgov-800width.jpg" title="CPR Robot 4"><img src="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841715157_Fig5--rgov-66x44.jpg" alt="CPR Robot 4"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Homography rectangle</div> <div class="imageCredit">UMD</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Aniket&nbsp;Bera</div> <div class="imageTitle">CPR Robot 4</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841759225_Fig6--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841759225_Fig6--rgov-800width.jpg" title="CPR Robot 5"><img src="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841759225_Fig6--rgov-66x44.jpg" alt="CPR Robot 5"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Thermal images generated by the thermal camera</div> <div class="imageCredit">UMD</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Aniket&nbsp;Bera</div> <div class="imageTitle">CPR Robot 5</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841798558_Fig7--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841798558_Fig7--rgov-800width.jpg" title="CPR Robot 6"><img src="/por/images/Reports/POR/2021/2031901/2031901_10676375_1622841798558_Fig7--rgov-66x44.jpg" alt="CPR Robot 6"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Trajectories</div> <div class="imageCredit">UMD</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Aniket&nbsp;Bera</div> <div class="imageTitle">CPR Robot 6</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our main contributions in this work are:  1. A mobile robot system that detects breaches in social distancing norms, autonomously navigates towards groups of non-compliant people and encourages them to maintain at least 6 feet of distance. We demonstrate that our mobile robot monitoring system is effective in terms of detecting social distancing breaches in static indoor scenes and can enforce social distancing in all of the detected breaches. Furthermore, our method does not require humans to wear any tracking or wearable devices.     2. We also integrated a CCTV setup in indoor scenes (if available) with the COVID-robot to further increase the area being monitored and improve the accuracy of tracking and pursuing dynamic non-compliant pedestrians. This hybrid combination of statically mounted cameras and a mobile robot can further improve the number of breaches detected and enforcements by up to 100%.     3. We presented a novel real-time method to estimate distances between people in images captured using an RGB-D camera on the robot and CCTV camera using a homography transformation. The distance estimate has an average error of 0.3 feet in indoor environments.     4. We also presented a novel algorithm for classifying noncompliant people into different groups and selecting a goal that makes the robot move to the vicinity of the largest group and enforce social distancing norms.     5. We integrated a thermal camera with the robot and wirelessly transmit the thermal images to appropriate security/healthcare personnel. The robot does not record temperatures or perform any form of person recognition to protect people?s privacy.     We have evaluated our method quantitatively in terms of the accuracy of localizing a pedestrian, the number of social distancing breaches detected in static and mobile pedestrians, and our CCTV-robot hybrid system. We also measure the time duration for which the robot can track a dynamic pedestrian. Qualitatively, we highlight the trajectories of the robot pursuing dynamic pedestrians when using only its RGB-D sensor as compared to when both the CCTV and RGB-D cameras are used.          Last Modified: 06/04/2021       Submitted by: Aniket Bera]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
