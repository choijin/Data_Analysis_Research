<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: RI: Matching Image Features with Correctness Predictions</AwardTitle>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>127955.00</AwardTotalIntnAmount>
<AwardAmount>127955</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The project develops methods for measuring the correctness of image-feature correspondences, which helps systems to identify good and bad correspondences. The project investigates robust estimators and 3D-point cloud compression algorithms that leverage the correctness measures of image-feature correspondences to increase their effectiveness. The developed methods can have many applications, such as image stitching for the creation of panoramas, 3D model reconstruction from photo collections, vision-based navigation in self-driving cars and robots, and augmented reality. The project integrates research with education by developing 3D computer vision courses and involving undergraduate and graduate students in this fundamental research effort. &lt;br/&gt;&lt;br/&gt;This research develops theoretically grounded confidence measures for classifiers using the statistical theory of extreme values. In particular, the project investigates confidence measures for the nearest neighbor classifier, a widely used classifier in many computer vision and other applications. The project investigates the confidence measures in two computer vison tasks: robust estimation and scene compression. The research focuses on using the developed confidence measures to enable the adaptive use of non-minimal samples for hypotheses generation and fast convergence in RANSAC-based estimators. Furthermore, the project develops a scene-compression algorithm based on a convex optimization method, of which objective function considers spatial coverage and visual distinctiveness. The project studies ways to enforce visual distinctiveness using confidence measures derived from this work and applies them to different applications to demonstrate the robustness and efficiency of estimating the correctness of image-feature correspondences.</AbstractNarration>
<MinAmdLetterDate>02/16/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/15/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1657179</AwardID>
<Investigator>
<FirstName>Gianfranco</FirstName>
<LastName>Doretto</LastName>
<EmailAddress>gianfranco.doretto@mail.wvu.edu</EmailAddress>
<StartDate>07/15/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Victor</FirstName>
<LastName>Fragoso</LastName>
<EmailAddress>victor.fragoso@mail.wvu.edu</EmailAddress>
<StartDate>02/16/2017</StartDate>
<EndDate>07/15/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>West Virginia University Research Corporation</Name>
<CityName>Morgantown</CityName>
<ZipCode>265066845</ZipCode>
<PhoneNumber>3042933998</PhoneNumber>
<StreetAddress>P.O. Box 6845</StreetAddress>
<CountryName>United States</CountryName>
<StateName>West Virginia</StateName>
<StateCode>WV</StateCode>
</Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
</Appropriation>
</Award>
</rootTag>
