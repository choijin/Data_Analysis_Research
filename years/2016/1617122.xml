<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Collaborative Research: Teleoperation with Passive, Transparent Force Feedback for MR-Guided Interventions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>180000.00</AwardTotalIntnAmount>
<AwardAmount>180000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Magnetic resonance imaging (MRI) is a widely used diagnostic tool that provides physicians with a remarkable extension to their natural vision, offering unparalleled high-definition visuals which enable soft tissue pathophysiology diagnosis, lesion delineation, and therapy monitoring without ionizing radiation.  Increasingly, physicians would like to use MRI not only for diagnosis but also for guided procedures like biopsy or tumor ablation, for greater accuracy.  However, the MR bore's geometry compels the physician to stand outside and transmit motions and forces remotely to tools operating on the patient within.  So although MR provides superior imaging, the sense of touch is absent.  To overcome this deficiency and achieve telepresence, physicians require a high-fidelity force-reflecting teleoperation system.  Added challenges are imposed by MR's intense magnetic field; ferromagnetic materials and electronics with current flow must be avoided, and even non-ferrous metals can produce imaging artifacts, which constrains the choice of actuators, transmissions, and sensors.   The PIs' goal in this project is to empower physicians to operate as if they were directly in contact with their patients, by integrating real-time 3D tissue imaging with kinesthetic and force feedback for physical interactions.  Project outcomes have the potential to directly affect a large population, because the high-fidelity force transmission developed here will be applicable to other image-guided interventions such as drug delivery and ultrasound.  The hybrid hydrostatic transmission will be applicable to (and indeed was initially conceived for) interactive human-safe robots; advances made in adapting it to MR-guided interventions will allow maturation of the technology and reductions in size and cost that will help push it into additional fields like medical robotics and bilateral teleoperation.  &lt;br/&gt;&lt;br/&gt;This research represents a collaboration among experts in robotics, haptics and interventional radiology.  The work will build upon and extend a novel bilateral teleoperator based on hydrostatic and pneumatic elements with rolling diaphragm actuators that provides a unique combination of low inertia, passivity, high stiffness and transparency, and negligible friction and backlash, and which is ideally suited to provide kinesthetic and force feedback between a physician outside the MR bore and tools operating on a patient within, allowing physicians to feel tissue property variations, for example.  Sensitive, dexterous tasks will be realizable with a passive teleoperator if it is sufficiently stiff and light.  MR-guided interventions are a compelling application for the proposed hybrid transmission because of MR's particular constraints, which as noted above rule out many other technologies.   A key question this research addresses is how to scale the promising performance of single-axis prototypes to a complex multi-axis system able to perform MR-guided procedures.   The PIs will combine kinematic and dynamic analyses with user tests for ergonomics to ensure that it supports intuitive motions and provides transparent feedback while fitting inside the MR bore's constrained space.  They will integrate the teleoperated system's motions with MR images via compatible sensors and imaging fiducials to provide visual feedback and prevent accidental intrusion into undesirable regions while the physician focuses on tool tip interactions.  Together, the novel force-reflecting transmission, kinematic mechanism, sensors, and software constitute a cyber-human system with unprecedented capabilities.  This telepresence system will be an ideal platform to expand scientific understanding of the impact that transmission transparency provides for MR-guided interventions.</AbstractNarration>
<MinAmdLetterDate>08/04/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1617122</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Whitney</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John P Whitney</PI_FULL_NAME>
<EmailAddress>j.whitney@northeastern.edu</EmailAddress>
<PI_PHON>6173732508</PI_PHON>
<NSF_ID>000710080</NSF_ID>
<StartDate>08/04/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155000</ZipCode>
<StreetAddress><![CDATA[360 Huntington Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~180000</FUND_OBLG>
</Award>
</rootTag>
