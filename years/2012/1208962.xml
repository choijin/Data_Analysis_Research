<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Functional Depth and Quantiles: Limit Theory, Comparisons and Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>100000.00</AwardTotalIntnAmount>
<AwardAmount>100000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This investigator proposes to study functional depth and functional quantiles using techniques developed for Empirical Process theory. Some recent techniques developed by this investigator and his colleagues allow one to obtain central limit theorems for quantile processes formed from functional data, and even can be applied to introduce new methods in the study of finite dimensional data, obtaining interesting variations on already existing examples of data depth. Moreover, within the context of functional depth,  this has uncovered some unforeseen problems. One such problem is that for natural processes, such as Brownian motion, and for some natural definitions of depth, one might have depth which is identically zero. Together with colleagues, this investigator has introduced a certain type of smoothing which allows one to eliminate this problem in many special cases. However, it is still necessary to develop a general, realistic, and usable approach for a wide variety of circumstances. So, in addition to developing an asymptotic theory for functional data, this project proposes to develop a coherent methodology for smoothing/modifying the data to allow for such analyses.&lt;br/&gt;&lt;br/&gt;The contemporary statistician must deal with data that appears in many quite different forms. Much energy has been spent on one-dimensional data, and researchers have achieved a great deal of success. While there are still many important questions in this area, the analysis of finite-dimensional data has also become a vibrant and important area for research. One critical difference between one-dimensional data and finite dimensional data is the lack of an obvious ordering of the data  in dimensions greater than one. To alleviate this problem, and better analyze (finite) multidimensional data, the concept of data depth has been introduced and studied by many authors. There are a variety of examples of such depth, each with its own set of good properties. One can choose a particular data depth to analyze a given data problem, depending on which properties are the most important. One can also compare various forms of depth on the same set of data to find contrasts that otherwise may not be apparent.  As this area has matured, so has the ability of the researcher to better fit the type of depth to the problem at hand. Even more recently, due to improved computing tools, real time monitoring of many processes is available and consequently, there is a growing need to analyze such data. This is often referred to as functional data. In mathematical parlance, this is considered infinite dimensional data. Data of this type occur, for example, in medicine, neuroscience, chemometrics, signal transmission, stock markets and meteorology. A robust methodology is important to successfully handle the resulting problems, and as is to be expected, this requires methods beyond those used to study the finite dimensional situation.  It is not surprising to a researcher in statistics or mathematics, that like many other infinite dimensional problems, infinite dimensional depth is fraught with differences and difficulties not found in the finite dimensional setting. The techniques proposed by this investigator to study functional data partially rely on a theory in which this investigator has made many contributions, and which is, now, quite well developed. These techniques have already allowed this investigator and his colleagues to uncover some of the difficulties that must be overcome.</AbstractNarration>
<MinAmdLetterDate>08/29/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/08/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208962</AwardID>
<Investigator>
<FirstName>Joel</FirstName>
<LastName>Zinn</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joel Zinn</PI_FULL_NAME>
<EmailAddress>jzinn@math.tamu.edu</EmailAddress>
<PI_PHON>9795752258</PI_PHON>
<NSF_ID>000157449</NSF_ID>
<StartDate>08/29/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M University</Name>
<CityName>College Station</CityName>
<ZipCode>778454375</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Pkwy South</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>020271826</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A &amp; M UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042915991</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M University Main Campus]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433368</ZipCode>
<StreetAddress><![CDATA[3368 TAMU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~25805</FUND_OBLG>
<FUND_OBLG>2013~53889</FUND_OBLG>
<FUND_OBLG>2014~20306</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The introduction of functional depth was in many ways motivated by the need to study, e.g., streaming data in fields such as medical imaging, meteorology, chemometrics and signal transmission as well as the study of stock market data and audience rating data. Understanding when a given depth can reliably give users in each of these fields useful and usable information is necessary to avoid improper conclusions.&nbsp;</p> <p><span>The study of this functional data, is quite different from those involving data with only a finite number of &ldquo;characteristics&rdquo;. Such a study, in addition to requiring different techniques must also deal with phenomena which does not appear in the finite characteristic case. Given the inability to use the important property of ordering data with one characteristic, in the finite characteristic case relatively new methods had to be devised. The introduction of depth functions has proved quite useful. However in the case of functional data the analogues of depth functions often incur a problem of degeneracy, which makes their application through empirical data suspect. The PI&rsquo;s work makes the case that the degeneracy problem is ubiquitous and, in several important cases, introduces a method for eliminating such degeneracy. &nbsp;</span></p> <p><span>Since the study of functional depth is a relatively new field, which has many new pitfalls, there is the need for a more intense study of this area. Certainly this will require a concerted effort by those presently involved in this study. But, it also requires &ldquo;the old guard&rdquo; to pass on their knowledge of this field, with all of its new obstructions to useful analysis and derived conclusions, to a new generation of researchers. Further, in order to test the efficacy of the newly derived methods, data from many of the fields mentioned above should be made available and their value jointly analyzed.</span></p> <div><span><br /></span></div> <p>&nbsp;</p><br> <p>            Last Modified: 12/09/2015<br>      Modified by: Joel&nbsp;Zinn</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The introduction of functional depth was in many ways motivated by the need to study, e.g., streaming data in fields such as medical imaging, meteorology, chemometrics and signal transmission as well as the study of stock market data and audience rating data. Understanding when a given depth can reliably give users in each of these fields useful and usable information is necessary to avoid improper conclusions.   The study of this functional data, is quite different from those involving data with only a finite number of "characteristics". Such a study, in addition to requiring different techniques must also deal with phenomena which does not appear in the finite characteristic case. Given the inability to use the important property of ordering data with one characteristic, in the finite characteristic case relatively new methods had to be devised. The introduction of depth functions has proved quite useful. However in the case of functional data the analogues of depth functions often incur a problem of degeneracy, which makes their application through empirical data suspect. The PIÃ†s work makes the case that the degeneracy problem is ubiquitous and, in several important cases, introduces a method for eliminating such degeneracy.    Since the study of functional depth is a relatively new field, which has many new pitfalls, there is the need for a more intense study of this area. Certainly this will require a concerted effort by those presently involved in this study. But, it also requires "the old guard" to pass on their knowledge of this field, with all of its new obstructions to useful analysis and derived conclusions, to a new generation of researchers. Further, in order to test the efficacy of the newly derived methods, data from many of the fields mentioned above should be made available and their value jointly analyzed.            Last Modified: 12/09/2015       Submitted by: Joel Zinn]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
