<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Analytic Support for the Geoscience Education and Diversity Program</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>112000.00</AwardTotalIntnAmount>
<AwardAmount>112000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>06000001</Code>
<Directorate>
<Abbreviation>GEO</Abbreviation>
<LongName>Directorate For Geosciences</LongName>
</Directorate>
<Division>
<Abbreviation>GEO</Abbreviation>
<LongName>Directorate For Geosciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jill L. Karsten</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The American Institutes for Research is synthesizing the major findings of selected projects in the Opportunities for Enhancing Diversity in the Geosciences (OEDG) Program portfolio, supported by NSF since 2002. Results of this synthesis will be used to inform the Committee of Visitors (COV) review of the Geoscience Education and Diversity (Geo E&amp;D) Program in January 2013. The project emphasizes knowledge generated by a carefully selected subgroup of projects from OEDG's program portfolio ? projects selected because of the relatively high validity and generalizability of their findings. A team of AIR researchers is reviewing a variety of reference materials for the selected projects, including final NSF reports, annual NSF reports, publications in peer-reviewed journals, and project websites. Telephone interviews with a sample of principal investigators are being used to flesh out the details of best practices and to follow up on institutionalization, model replication, and longer term outcomes for participants after NSF funding expires. Results of the review and interviews are being summarized in a final report that identifies evidence-based successful strategies in achieving OEDG program goals and the conditions under which they succeeded.  This project builds on the project-level findings reported in the 2007 Journal of Geosciences Education special issue on the status of racial diversity in the geosciences and expands on the two articles in that volume that addressed lessons learned and best practices gleaned from results of Federal research investments made during the previous decade. Since publication of the special issue of JGE, projects funded by OEDG have built on the body of knowledge presented therein, making this systematic, scholarly assessment and synthesis of the most significant findings of projects supported by OEDG very timely. This project, relying on the most significant, high-quality research supported by OEDG over its history, is expected to clarify best practices in fostering minority participation in the geosciences and the conditions under which various strategies are most likely to succeed. Analysis of new knowledge, understanding, and best practices will benefit substantially the 2013 COV, NSF GEO E&amp;D Program managers, current OEDG projects, the broader geosciences community, and other NSF minority-serving programs.</AbstractNarration>
<MinAmdLetterDate>08/23/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/23/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.050</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1251305</AwardID>
<Investigator>
<FirstName>Joan</FirstName>
<LastName>Ruskus</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joan Ruskus</PI_FULL_NAME>
<EmailAddress>jruskus@air.org</EmailAddress>
<PI_PHON>6508438112</PI_PHON>
<NSF_ID>000569961</NSF_ID>
<StartDate>08/23/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>American Institutes for Research in the Behavioral Sciences</Name>
<CityName>Arlington</CityName>
<ZipCode>222023289</ZipCode>
<PhoneNumber>2024035000</PhoneNumber>
<StreetAddress>1400 Crystal Drive</StreetAddress>
<StreetAddress2><![CDATA[10th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041733197</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AMERICAN INSTITUTES FOR RESEARCH IN THE BEHAVIORAL SCIENCES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041733197</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[American Institutes for Research in the Behavioral Sciences]]></Name>
<CityName>San Mateo</CityName>
<StateCode>CA</StateCode>
<ZipCode>944032555</ZipCode>
<StreetAddress><![CDATA[2800 Campus Drive, Suite 200]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA14</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1697</Code>
<Text>OPPORT FOR ENHANCING DIVERSITY</Text>
</ProgramElement>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~112000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to provide information about evidence-based best practices for management of the Geoscience Education and Diversity (Geo E&amp;D) Program of the National Science Foundation (NSF).&nbsp; This information was intended to assist managers in preparing for the 2013 Committee of Visitors (COV) review of the Opportunities for Enhancing Diversity in the Geosciences (OEDG) Program portfolio. &nbsp;The OEDG Program addressed disparities in the rates at which members of different groups within the U.S. population are prepared for and participate in geoscience careers. &nbsp;Although most OEDG projects had conducted evaluations of their own and reported their findings in annual and final reports, those data had never been systematically reviewed for validity, nor had particularly strong projects been identified using the quality of evaluation data as the key criterion.</p> <p>&nbsp;</p> <p>For the purposes of this study, we only considered OEDG projects that had moved beyond the exploratory/proof of concept stage (designated as &ldquo;Track 2 projects&rdquo;).&nbsp; Also, projects had to have been operational for at least two years to allow time to measure project outcomes.&nbsp; Using these criteria, we reviewed a group of 32 projects, which included 46 individual OEDG awards (some projects included multiple awards).&nbsp;</p> <p>&nbsp;</p> <p>Our review process began with a critical reading of project deliverables&mdash;annual and final reports, evaluation reports, and peer-reviewed publications.&nbsp; PhD-level individuals conducted this review, all of whom had extensive evaluation experience.&nbsp; More than one individual reviewed most of the projects.&nbsp; We identified a final set of 14 projects as having employed &ldquo;best practices.&rdquo;&nbsp; In order to qualify as a best practice, the project needed to provide sound evidence that their intervention(s) had significant impact on their target audience(s).&nbsp; Interviews were conducted with project PIs, and in some cases project managers and evaluators, to collect more information about project interventions, details of their evaluations, post-NSF sustainability and replication, and lessons learned.&nbsp; Once best practices employed by the selected projects were identified, we profiled them in a report to NSF.&nbsp; The history of each project was summarized (including partners, funding, duration, prior awards, and other pertinent information); the institutional context was described; the target audience(s) were identified; the intervention(s) were described; the evaluation findings were presented; continuation efforts and status were discussed; and notable features of the projects were presented.&nbsp; As a final step, we looked across the 14 projects and identified common features of many of the projects.&nbsp;</p> <p>&nbsp;</p> <p>Looking across the best practices projects that we studied, we were able to identify ten notable themes.&nbsp; The five most prevalent were:</p> <ol> <li>A strong evaluation component.&nbsp; In every case evaluation was taken very seriously, both to improve project functioning year to year and to document impact.&nbsp; PIs often credited their evaluations for helping them obtain continuation funding or related grants.&nbsp; </li> <li>Involvement of practicing scientists and real data.&nbsp; Enabling participants to &ldquo;do&rdquo; science was central to these projects&rsquo; strategies.&nbsp; </li> <li>Clear model of intervention.&nbsp; Best practice projects all had coherent intervention models, targeting resources to logically linked components. </li> <li>Consistency. &nbsp;None of these projects evidenced &ldquo;treatment drift&rdquo;&mdash;their models were implemented as originally intended with only minor modifications.&nbsp; </li> <li>Sustainability.&nbsp; The majority of projects were able to sustain some aspects of their projects at some level&...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to provide information about evidence-based best practices for management of the Geoscience Education and Diversity (Geo E&amp;D) Program of the National Science Foundation (NSF).  This information was intended to assist managers in preparing for the 2013 Committee of Visitors (COV) review of the Opportunities for Enhancing Diversity in the Geosciences (OEDG) Program portfolio.  The OEDG Program addressed disparities in the rates at which members of different groups within the U.S. population are prepared for and participate in geoscience careers.  Although most OEDG projects had conducted evaluations of their own and reported their findings in annual and final reports, those data had never been systematically reviewed for validity, nor had particularly strong projects been identified using the quality of evaluation data as the key criterion.     For the purposes of this study, we only considered OEDG projects that had moved beyond the exploratory/proof of concept stage (designated as "Track 2 projects").  Also, projects had to have been operational for at least two years to allow time to measure project outcomes.  Using these criteria, we reviewed a group of 32 projects, which included 46 individual OEDG awards (some projects included multiple awards).      Our review process began with a critical reading of project deliverables&mdash;annual and final reports, evaluation reports, and peer-reviewed publications.  PhD-level individuals conducted this review, all of whom had extensive evaluation experience.  More than one individual reviewed most of the projects.  We identified a final set of 14 projects as having employed "best practices."  In order to qualify as a best practice, the project needed to provide sound evidence that their intervention(s) had significant impact on their target audience(s).  Interviews were conducted with project PIs, and in some cases project managers and evaluators, to collect more information about project interventions, details of their evaluations, post-NSF sustainability and replication, and lessons learned.  Once best practices employed by the selected projects were identified, we profiled them in a report to NSF.  The history of each project was summarized (including partners, funding, duration, prior awards, and other pertinent information); the institutional context was described; the target audience(s) were identified; the intervention(s) were described; the evaluation findings were presented; continuation efforts and status were discussed; and notable features of the projects were presented.  As a final step, we looked across the 14 projects and identified common features of many of the projects.      Looking across the best practices projects that we studied, we were able to identify ten notable themes.  The five most prevalent were:  A strong evaluation component.  In every case evaluation was taken very seriously, both to improve project functioning year to year and to document impact.  PIs often credited their evaluations for helping them obtain continuation funding or related grants.   Involvement of practicing scientists and real data.  Enabling participants to "do" science was central to these projectsÃ† strategies.   Clear model of intervention.  Best practice projects all had coherent intervention models, targeting resources to logically linked components.  Consistency.  None of these projects evidenced "treatment drift"&mdash;their models were implemented as originally intended with only minor modifications.   Sustainability.  The majority of projects were able to sustain some aspects of their projects at some level&mdash;from full institutionalization to continuation of a piece of the model or the spirit of the project.      Five other themes were apparent in some (at least half) of the projects:  Leveraging of funds,  Financial support for students and faculty, Selective recruitment of students, Development of a sense of community, and  Close worki...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
