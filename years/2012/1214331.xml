<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Data Cleaning as a Service</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Glenn H. Larsen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project aims to do preliminary feasibility study to be eventually able to offer scalable data cleaning service in the Cloud Computing environment for small businesses. Despite active research on data cleaning and available commercial data cleaning solutions, many small businesses are unable to clean their in-house data to the satisfactory level due to various reasons. Often, small businesses simply do not have human or IT resources for cleaning their data. Toward these challenges, in this SBIR Phase I proposal, we claim that by extending existing state-of-the-art data cleaning solutions to be more scalable and be available in the Cloud Computing environment and offering data cleaning as a service as in Software-as-a-Service (SaaS) paradigm, small businesses can afford to have easy access to sophisticated data cleaning service for nominal fees. This effort will extend current software infrastructure to build high performance data cleaning solutions, which will be the fundamental basis of many data quality problems. Its intellectual merits lie in establishing a unifying framework that improves the scalability in data cleaning solutions and extend them to fit into the Cloud Computing environment.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project can be far reaching since the issues of data quality are ubiquitous in many businesses. With the explosive increase of data size as in "Big Data" in virtually all industries and disciplines, in particular, the ability to do the scalable execution of rich data cleaning solutions becomes ever more important. By offering such scalable data cleaning solutions in the Cloud Computing environment as chargeable service, this SBIR project aims to reach many small businesses that need to clean their complex in-house data without much investment. By implementing the whole cleaning-as-a-service using Amazon's web service infrastructure such as EC2, the company believes that the project has a great commercial potential to serve the market that did not exist before.</AbstractNarration>
<MinAmdLetterDate>06/12/2012</MinAmdLetterDate>
<MaxAmdLetterDate>10/23/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1214331</AwardID>
<Investigator>
<FirstName>Hyunjeong</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hyunjeong Lee</PI_FULL_NAME>
<EmailAddress>hleenittany@gmail.com</EmailAddress>
<PI_PHON>8144416122</PI_PHON>
<NSF_ID>000545828</NSF_ID>
<StartDate>06/12/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Nittany System Research, LLC</Name>
<CityName>State College</CityName>
<ZipCode>168017807</ZipCode>
<PhoneNumber>8144416122</PhoneNumber>
<StreetAddress>220 Kennedy St.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832112697</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NITTANY SYSTEM RESEARCH, LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Nittany System Research, LLC]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>168017807</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8031</Code>
<Text>Education Products</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The SBIR Phase I project (Data Cleaning as a Service) ran from July 2012 to June 2013, led by Nittany System Research, LLC and collaborated with Penn State.</p> <p>The project aimed at investigating and developing novel Cloud-based data cleaning service using the pay-as-you-go model. The term "data cleaning" in general refers to the task of detecting and correcting inaccurate records in a database so that subsequent business analysis can be performed based on more accurate data. While there are many existing solutions to the problem of data cleaning, our solution is in particular novel as follows. First, being entirely Cloud-based, businesses can clean  their data by simply uploading their data to the Cloud and cleaning them within the Cloud. Second, our solution is very scalable as it runs using multiple machines in parallel based on MapReduce framework.&nbsp;</p> <p>Based on these two key ideas, PIs have built a prototype of the Cloud-based de-duplication system, named as Dedool (for <span style="text-decoration: underline;">ded</span>uplication t<span style="text-decoration: underline;">ool</span>), using Amazon.com&rsquo;s Cloud infrastructure (AWS).The prototype is accessible to public at http://www.dedool.com/.</p> <p>In addition, PIs have investigated about novel ways to monitor and optimize parallel environment such as MapReduce so that one can run a very large amount of cleaning tasks more efficiently. Finally, PIs have identified the need to be able to do cleaning in the Cloud while      providing anonymity to the data being cleaned.This way, businesses using the proposed Dedool service do not need to worry about the privacy issue of their potentially sensitive data.</p> <ul> </ul> <div dir="ltr"><span style="font-size: small;">Overall, the project has hired and trained a total of six developers, and produced four research publications (three published and one under review).<br /></span></div><br> <p>            Last Modified: 08/15/2013<br>      Modified by: Hyunjeong&nbsp;Lee</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618323681_Untitled2--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618323681_Untitled2--rgov-800width.jpg" title="Dedool-main"><img src="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618323681_Untitled2--rgov-66x44.jpg" alt="Dedool-main"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Dedool.com main screenshot</div> <div class="imageCredit">NSR</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Hyunjeong&nbsp;Lee</div> <div class="imageTitle">Dedool-main</div> </div> </li> <li> <a href="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618238705_Untitled1--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618238705_Untitled1--rgov-800width.jpg" title="Dedool1"><img src="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618238705_Untitled1--rgov-66x44.jpg" alt="Dedool1"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Uploading and managing files to clean</div> <div class="imageCredit">NSR</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Hyunjeong&nbsp;Lee</div> <div class="imageTitle">Dedool1</div> </div> </li> <li> <a href="/por/images/Reports/POR/2013/1214331/1214331_10181022_1376618569353_Untitled3--rgov-214x...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The SBIR Phase I project (Data Cleaning as a Service) ran from July 2012 to June 2013, led by Nittany System Research, LLC and collaborated with Penn State.  The project aimed at investigating and developing novel Cloud-based data cleaning service using the pay-as-you-go model. The term "data cleaning" in general refers to the task of detecting and correcting inaccurate records in a database so that subsequent business analysis can be performed based on more accurate data. While there are many existing solutions to the problem of data cleaning, our solution is in particular novel as follows. First, being entirely Cloud-based, businesses can clean  their data by simply uploading their data to the Cloud and cleaning them within the Cloud. Second, our solution is very scalable as it runs using multiple machines in parallel based on MapReduce framework.   Based on these two key ideas, PIs have built a prototype of the Cloud-based de-duplication system, named as Dedool (for deduplication tool), using Amazon.comÃ†s Cloud infrastructure (AWS).The prototype is accessible to public at http://www.dedool.com/.  In addition, PIs have investigated about novel ways to monitor and optimize parallel environment such as MapReduce so that one can run a very large amount of cleaning tasks more efficiently. Finally, PIs have identified the need to be able to do cleaning in the Cloud while      providing anonymity to the data being cleaned.This way, businesses using the proposed Dedool service do not need to worry about the privacy issue of their potentially sensitive data.   Overall, the project has hired and trained a total of six developers, and produced four research publications (three published and one under review).        Last Modified: 08/15/2013       Submitted by: Hyunjeong Lee]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
