<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: CHS: Medium: Collaborative Research: Improving Pedestrian Safety in Urban Cities using Intelligent Wearable Systems</AwardTitle>
<AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>320782.00</AwardTotalIntnAmount>
<AwardAmount>320782</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Erik Brunvand</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Using smartphones while walking poses an increasingly common safety problem for people in urban environments. Whether listening to music, texting, or talking, pedestrians that are absorbed with their smartphones are considerably less likely to notice important auditory cues of danger, such as the honks and sounds of approaching vehicles, putting pedestrians at far greater risk of being hit. This project aims to develop an intelligent wearable system that uses miniature microphones - embedded in earphones or headsets - to detect and locate approaching vehicles and warn the wearer of imminent dangers from cars, buses, motorbikes, trucks, and trams. &lt;br/&gt;&lt;br/&gt;The system comprises multiple microphones embedded in a wearable headset, an ultra-low-power feature extraction and data  processing pipeline, and a set of machine-learning classifiers running on a smartphone. This project is organized in four research thrusts: (1) designing an architecture and data processing pipeline for a wearable system composed of heterogeneous embedded modules; (2) devising an ultra-low-power, analog, signal-processing application-specific integrated circuit (ASIC) for energy-efficient, on-board feature extraction; (3) modeling and optimizing machine-learning classifiers for acoustic event detection and localization; and (4) designing an interface and feedback mechanisms that are optimized for the users' perceptual, cognitive, and motor control abilities.&lt;br/&gt;&lt;br/&gt;This research will help reduce pedestrian injuries and fatalities, and expand knowledge on designing wearable systems for enhancing safety in cities, workplaces, and the home. The underlying framework can be generalized to other systems - employing low-power signal processors and algorithms to solve real-time sensing and classification problems of many kinds. Research products will be made publicly available to anyone to apply these techniques in their own system designs. Course modules developed on embedded systems, mobile computing, and Internet-of-Things will be used at the three participating universities to train undergraduate and graduate students, and will be made available online.</AbstractNarration>
<MinAmdLetterDate>05/26/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/17/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1704469</AwardID>
<Investigator>
<FirstName>Shahriar</FirstName>
<LastName>Nirjon</LastName>
<EmailAddress>nirjon@cs.unc.edu</EmailAddress>
<StartDate>05/26/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
</Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
