<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Understanding Human Performance Consequences of Using Headworn Displays for Large Assemblies</AwardTitle>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>499984.00</AwardTotalIntnAmount>
<AwardAmount>499984</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The field of construction is increasingly interested in head worn displays (HWDs) that might provide construction workers with augmented reality (AR) information such as blueprints or overlaid annotations and instructions.  However, these HWDs might not have the desired effects of improved safety and efficiency: they could instead interfere physically or mentally with the job at hand, reducing workers' situational awareness.  This project is about better understanding the design and effects of AR HWDs for common construction tasks such as framing and sheathing.  The team will work with industry partners to understand the needs and risks workers face in order to develop task-specific AR interfaces as well as ways to measure safety, efficiency, awareness, and satisfaction.  They will then evaluate and refine both the interfaces and measures in a series of controlled experiments that evaluate the interfaces in a large motion-capture lab at the PIs' home institution.  The goal is to provide a generally useful suite of tasks, interfaces, measures, and guidelines for AR HWDs in construction and beyond.  The team will also partner with the Building Women in Construction organization to develop AR experiences for middle and high school students that use the technology for outreach and education. &lt;br/&gt;&lt;br/&gt;The team will start by working with a stakeholder group to develop meaningful metrics of efficiency using interviews and review of stakeholder quality control documents.  Based on preliminary work, and the team's access to motion capture equipment, these are likely to go beyond time taken and errors made and include factors such as tool and material choice, positioning and use, and damage.  They will also develop specific measures of situational awareness, workload, and usability based on existing guidelines and scales, conducting pilot user studies to refine them and ensure that they can be administered in the simulated environment.  The interfaces and experimental testbed will be developed using the motion capture lab facilities and commodity AR HWD devices: developing both conformal and non-conformal AR interfaces at different levels of fidelity and at different scales; simulating the hazards and distractions of a real construction site through including real and simulated objects and noises; and developing methods to track both behavior and object use.  These will be evaluated in a series of controlled experiments using a balanced Latin Squares design, varying the presentation of information (including a control version using paper blueprints) and the scale of the conformal elements relative to the task area.  The team will compute metrics developed in earlier stages and conduct interviews to get at participants' subjective satisfaction, engagement, perceptions of usability, and ideas for improvements.  For the education and outreach portions of the project, they will also develop a smaller-scale AR HWD exercise to support a spaghetti bridge construction task commonly used in schools.</AbstractNarration>
<MinAmdLetterDate>08/04/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2017</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1718051</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Gabbard</LastName>
<EmailAddress>jgabbard@vt.edu</EmailAddress>
<StartDate>08/04/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tanyel</FirstName>
<LastName>Bulbul</LastName>
<EmailAddress>tanyel@vt.edu</EmailAddress>
<StartDate>08/04/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Polytechnic Institute and State University</Name>
<CityName>BLACKSBURG</CityName>
<ZipCode>240610001</ZipCode>
<PhoneNumber>5402315281</PhoneNumber>
<StreetAddress>Sponsored Programs 0170</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
</Appropriation>
</Award>
</rootTag>
